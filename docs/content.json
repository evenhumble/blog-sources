{"meta":{"title":"DIRTY HANDS QA","subtitle":"All Round Tester's Notes","description":"Learning, Practice,And Never minded","author":"dh-qa","url":"http:","root":"/"},"pages":[{"title":"","date":"2019-07-29T04:14:16.102Z","updated":"2019-06-27T07:40:14.345Z","comments":true,"path":"images/productivity/DateUtil.html","permalink":"http:/images/productivity/DateUtil.html","excerpt":"","text":"DateUtilFunctionsisSameDateCurrentYearCurrentMonthCurrentDayParserParse for DateParse For DateTimeFormatterFrom DateFrom DateTimeFrom CalendarXMind: ZEN - Trial Version"}],"posts":[{"title":"Xmind,Test Cases,and Allure templates for TDD","slug":"productivity/1-Junit5CaseTestTemplate","date":"2019-07-27T13:34:04.000Z","updated":"2019-07-29T04:21:47.678Z","comments":true,"path":"2019/07/27/productivity/1-Junit5CaseTestTemplate/","link":"","permalink":"http:/2019/07/27/productivity/1-Junit5CaseTestTemplate/","excerpt":"","text":"Xmind,TestCases and JUnit5 Allure TemplateLearn from the requirements and write test cases are the common daily work of a tester.Normally write the mind map as a guide of test cases(in internet it is enough), thenexecute the test cases or write testing codes based on the xmind file(mind map).But do you ever question about this process? It is productive enough? Is there any improvement? Let me give an example: I want to test a DateUtil functionality, it has several features, the mindmap like this: DateUtil Test Cases Mindmap: Then write test codes(your boss required you to write automation codes) using junit and allure: 12345678910111213141516171819@Epic(\"Hutool DateUtil Usage\")@Feature(\"Hutool DateUtil Simple Usage\")public class HutoolDateUtilsTest &#123; @Test @DisplayName(\"DateUtil-Formatter-From Date\") @Story(value =\"Formatter-From Date\" ) public void testFrom_Date()&#123; //write testing codes &#125; @Test @DisplayName(\"DateUtil-Formatter-From DateTime\") @Story(value =\"Formatter-From DateTime\" ) public void testFrom_DateTime()&#123; //write testing codes &#125;&#125; allure is a tool for unified test report. It is worth to use.Two conceptions in allure mapping to requirments: EPIC: A big functionality,usally have several small featuers Feature: A relative small functionality, which might have one or more user stories User Story: a small/independent functionality Writing code is actually transforming the test cases into codes, and labeling the test codes by different test cases names. Running the tests, the report is like: It is perfect! But don’t you think you write test cases twice? In xmind, and in code like @Story bla bla bla ….. Why do I write the annotations like @Story,@Epic or @Feature? The answer is that I want to make a fancy report,but I actually did duplicated work, didn’t I? Duplicate work have bad smell. In this case, it looks like you sacrifice your productivity to make report fancy. What if I want both fancy report and productivity? Is it possible to write once? Scripting Boy thought there should be a way. Become a scripting boy to connect these dotsActaully It is not that hard to find a way to achieve the goal: fancy report and productivity both.Let me figure it out: Export to test cases in markdown format through xmind(xmind has java/python sdk to manupilate the xmind file, but it is too complex), export is in xmind menu file&gt;export&gt;text: BTW: importing md file to xmind is in ``file&gt;import&gt;text12345678910The exported markdown file content:```sh# DateUtil## Functions### isSameDate### CurrentYear### CurrentMonth### CurrentDay Parse the markdown test cases, and render parsed test cases into testing code templateIt is not hard, there are only three files, and less than 50 lines of codes: pom.xml for leveraging existing libs 12345&lt;dependency&gt; &lt;groupId&gt;org.jtwig&lt;/groupId&gt; &lt;artifactId&gt;jtwig-core&lt;/artifactId&gt; &lt;version&gt;5.87.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; a junit test code template file in class path(resources folder),named junit_allure_template.twig 12345678910111213141516171819202122import io.qameta.allure.Epic;import io.qameta.allure.Story;import io.qameta.allure.Feature;import org.junit.jupiter.api.Assertions;import org.junit.jupiter.api.DisplayName;import org.junit.jupiter.api.Test;@Epic(\"&#123;&#123;context.epic&#125;&#125;\")@Feature(\"&#123;&#123;context.epic&#125;&#125;\")public class &#123;&#123;context.epic&#125;&#125;Test &#123; &#123;% for entry in context.features.entrySet() %&#125; &#123;% for feature in entry.value() %&#125; @Test @DisplayName(\"&#123;&#123;context.epic&#125;&#125;-&#123;&#123;feature.desc&#125;&#125;\") @Story(value =\"&#123;&#123;feature.desc&#125;&#125;\" ) public void test&#123;&#123;feature.name&#125;&#125;()&#123; //write testing codes &#125; &#123;% endfor %&#125; &#123;% endfor %&#125;&#125; 50 lines of codes, to read the exported markdown file, and render the template junit_allure_template.twig 123456789101112131415161718192021222324252627282930313233343536373839404142public class Junit5TestTemplateGenerator &#123; public static void generateJunit5TC(String mdFile,String fileName) throws IOException &#123; AllureTestModel allureTestModel = new AllureTestModel(); List&lt;String&gt; mdContent= Resources.readLines(Resources.getResource(mdFile),Charsets.UTF_8); String currentFeature=\"\"; for (String line : mdContent) &#123; if(line.startsWith(\"###\"))&#123; AllureFeature feature = new AllureFeature(); feature.setDesc(currentFeature+\"-\"+line.replace(\"###\",\"\").trim()); feature.setName(line.replace(\"###\",\"\").trim().replace(\" \",\"_\")); allureTestModel.features.get(currentFeature).add(feature); &#125;else if(line.startsWith(\"##\"))&#123; currentFeature = line.replace(\"##\",\"\").trim(); allureTestModel.features.putIfAbsent(currentFeature,new ArrayList&lt;&gt;()); &#125;else if(line.startsWith(\"#\"))&#123; allureTestModel.setEpic(line.replace(\"#\",\"\").trim()); &#125; &#125; JtwigTemplate template = JtwigTemplate.classpathTemplate(\"junit_allure_template.twig\"); JtwigModel model = JtwigModel.newModel().with(\"context\",allureTestModel); template.render(model,new FileOutputStream(new File(fileName+\".java\"))); &#125; @Data public static class AllureTestModel&#123; private String epic; private Map&lt;String,List&lt;AllureFeature&gt;&gt; features = new HashMap&lt;&gt;(); &#125; @Data public static class AllureFeature&#123; private String name; private String desc; &#125; public static void main(String[] args) throws IOException &#123; Junit5TestTemplateGenerator.generateJunit5TC(\"DateUtil.md\",\"HutoolDateUtilTest.java\"); &#125;&#125; And the result is: 1234567891011121314151617181920@Epic(\"Hutool DateUtil Usage\")@Feature(\"Hutool DateUtil Simple Usage\")public class HutoolDateUtilsTest &#123; @Test @DisplayName(\"DateUtil-Formatter-From Date\") @Story(value =\"Formatter-From Date\" ) public void testFrom_Date()&#123; //write testing codes &#125; @Test @DisplayName(\"DateUtil-Formatter-From DateTime\") @Story(value =\"Formatter-From DateTime\" ) public void testFrom_DateTime()&#123; //write testing codes &#125; ......&#125; which is same as your writing before. Scripting boy is not kidding you, use a JAVA template lib to make both fancy report and test cases real withoutduplicated work. detail codes, please refer junit5 code render It is not perfect solution which I need to admit. But it works somehow, and save my time anyway.It also demostrated that there are plenty opportunities to tester to practice coding skills,to know a little bit more about other libaries. It is not about rocket science, not about make a fancy product, it is just about practicing day in and day out to make life a little bit easier than before. What’s next?It looks good, not why not write it as a plugin of a modern ide like intellj IDEA. Wait, Wait, I am a scripting boy, try tomake a product? But Why not? And why not support more templates like testng or other testing framework? See you next time!","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http:/tags/JAVA/"},{"name":"Automation","slug":"Automation","permalink":"http:/tags/Automation/"},{"name":"TDD","slug":"TDD","permalink":"http:/tags/TDD/"}]},{"title":"测试的Python须知脑图","slug":"python/Python-Tester-Should-Know","date":"2019-07-27T13:34:04.000Z","updated":"2019-07-29T04:08:30.660Z","comments":true,"path":"2019/07/27/python/Python-Tester-Should-Know/","link":"","permalink":"http:/2019/07/27/python/Python-Tester-Should-Know/","excerpt":"","text":"下图是使用Python进行自动化测试需要了解的大纲.","categories":[],"tags":[{"name":"Automation","slug":"Automation","permalink":"http:/tags/Automation/"},{"name":"Python","slug":"Python","permalink":"http:/tags/Python/"}]},{"title":"","slug":"hbase-intro","date":"2019-07-11T01:44:13.646Z","updated":"2019-07-11T02:18:35.516Z","comments":true,"path":"2019/07/11/hbase-intro/","link":"","permalink":"http:/2019/07/11/hbase-intro/","excerpt":"","text":"What is HBASE NoSQL: Not Only SQL Column-Oriented Database Based on Google BigTable HDFS as Storage TB/PB data and Random Access 解决10条记录和1000千万记录同样的读写性能问题 RDBMS 问题 HBASE VS MYSQL Google Big Table12A Bigtable is a sparse, distributed, persistent multidimensional sorted map.The map is indexed by a row key, column key, and a timestamp; each value in the map is an uninterpreted array of bytes. map: bigtable 的核心就是一个Map，key-value persistent： 持久化和其他没有任何区别 distributed： 分布式文件系统(HDFS/S3/GFS)/多副本(replication) sorted: key是排序的 multidimensional： 和columns有对应关系, 第一层key-value,可以认为是个row, A,B 可以认为是Column Families 12345678910&#123; \"1\" : &#123; \"A\" : \"x\", \"B\" : \"z\" &#125;, \"aaaaa\" : &#123; \"A\" : \"y\", \"B\" : \"w\" &#125; &#125; sparse: 稀疏，字段不固定,null值不占空间 Tables,Rows,Columns and Cells Regionmap: key-value, 根据key可以直接找到对应值,o(1),但是内存不可能无限大,怎么办? Region Server Region,Region Server Region 根据不同表来切分 Region 放到不同的Region Server HBASE Column Family HBASE column family 每个column family 存成不同的文件 缓存/压缩/version HBASE架构-1存储基于Haddop/HDFS: HBASE架构-2Region Server/Region： HBASE架构-3 HBASE架构-4 zookeeper: 管理节点信息,hbase:meta信息 HBASE架构-5 HMASTER： 管理RegionServer节点，所有metadata变化的接口 HBASE架构-6客户端访问： HBASE架构-7Region Sever 内部结构： Regions: 123456Table (HBase table) Region (Regions for the table) Store (Store per ColumnFamily for each Region for the table) MemStore (MemStore for each Store for each Region for the table) StoreFile/HFILE (StoreFiles for each Store for each Region for the table) Block (Blocks within a StoreFile within a Store for each Region for the table) HBASE架构-8HBASE是CP系统，WAL(Write Ahead Log) HBASE table,rowkey,column family Region/Region Server Store/MemStore/StoreFile/HFILE/WAL Zookeeper/HMaster HBase CLIUse Hbase in CLI and JAVA to learning the basic usage of hbase: Use Hbase in a Local Mode Use Hbase in JAVA HBase Local Mode使用Hbase的本地模式相当简单，启动hbase就可以,不需要太多额外配置。 启动hbase 12cd $&#123;HBASE_HOME&#125;/binsh start-hbase.sh 使用hbase shell 访问 12345678910./hbase shellHBase ShellUse \"help\" to get list of supported commands.Use \"exit\" to quit this interactive shell.For Reference, please visit: http://hbase.apache.org/2.0/book.html#shellVersion 2.1.1, rb60a92d6864ef27295027f5961cb46f9162d7637, Fri Oct 26 19:27:03 PDT 2018Took 0.0336 secondsIgnoring executable-hooks-1.3.2 because its extensions are not built. Try: gem pristine executable-hooks --version 1.3.2Ignoring gem-wrappers-1.3.2 because its extensions are not built. Try: gem pristine gem-wrappers --version 1.3.22.4.1 :001 &gt; HBase Basic Commands create table with column family 1create 'test_table','cf1' put data: 插入数据： put ,,cf:property,1put 'test_table','row_key_1','cf1:k1','k1:v1' 同一个column family,不同数据，然后scan结果, scan的结果是cell-oriented 123456789101112 =&gt; [\"test_table\"]2.4.1 :004 &gt; put 'test_table','row_key_1','cf1:k1','k1:v1'Took 0.2186 seconds2.4.1 :005 &gt; put 'test_table','row_key_1','cf1:k2','k2:v2'Took 0.0094 seconds2.4.1 :006 &gt; put 'test_table','row_key_1','cf1:k3','k3:v3'Took 0.0032 seconds2.4.1 :007 &gt; scan 'test_table'ROW COLUMN+CELL row_key_1 column=cf1:k1, timestamp=1545926595556, value=k1:v1 row_key_1 column=cf1:k2, timestamp=1545926683964, value=k2:v2 row_key_1 column=cf1:k3, timestamp=1545926692956, value=k3:v3 get data 123452.4.1 :008 &gt; get 'test_table','row_key_1'COLUMN CELL cf1:k1 timestamp=1545926595556, value=k1:v1 cf1:k2 timestamp=1545926683964, value=k2:v2 cf1:k3 timestamp=1545926692956, value=k3:v3 以上实际上就是HBASE的最常用的使用方法: put/get(write/read)","categories":[],"tags":[]},{"title":"","slug":"loan-calculation","date":"2019-06-27T07:41:42.444Z","updated":"2019-06-27T07:41:42.444Z","comments":true,"path":"2019/06/27/loan-calculation/","link":"","permalink":"http:/2019/06/27/loan-calculation/","excerpt":"","text":"Loan Calculation Example Loan Rule Defintion Installment Calculation Overdue Calculation IRR Calculation Loan Rule Definition Installments Calculation repayment-Principal: ROUND(10000/3,2) repayment-interest: ROUND(10000*2%,2) Advanced Repayment calculationOverall Payment = Current Term Repayment + Remain Principal+ default penalty(10000*1%) Overdue Repayment calculationFor example: Last Term: 4-1 is the repayment day, but actually repayment is occurred in 4-10, then it is default. And the default fee is over your imagination. Term1 Default Penalty: ROUND(3333.33(0.02/30)*1.5(60+9),2) Term2 Default Penalty: ROUND(3333.33(0.02/30)*1.5(30+9),2) Term3 Default Penalty: ROUND(3333.34(0.02/30)*1.5(0+9),2) Don’t be default, man!! IRR Calculation","categories":[],"tags":[]},{"title":"","slug":"Thoughts-Be-A-Touch-Tester","date":"2019-06-27T07:41:42.443Z","updated":"2019-06-27T07:41:42.443Z","comments":true,"path":"2019/06/27/Thoughts-Be-A-Touch-Tester/","link":"","permalink":"http:/2019/06/27/Thoughts-Be-A-Touch-Tester/","excerpt":"","text":"Think in Testing 1: Be ToughIf someone tell you that software testing or quality assurance is an easy job to do, he/she might not understand what a tester or qa do. There are many perspective a tester or qa involved: Testing Requirement Clarification Dev Process/Release Process Planning Almost every phase QA is involved, it can burn you out easily. Here I just want to talk about some bad thing might happed, and why be tough is a basic charactor of a QA or Tester. Don’t Be a maidDon’t be a maid, and don’t spend too much time on other’s careless and irresponsibility.Need to fix it. In many Chinese domestic company, Tester and QA is a maid of Developer, everything could be in testing scope. Let me summarize several common cases: Some incomplete task, need to test Some codes never work, neet to test Some bug can’t be produced, need to test Some performance issues can’t be measured, need to test What ever the requirement is, no matter you tester invovled or not, send it to test And more important thing is that normally a tester/qa might face 5+ developers. If you can not be tough to Dev, your time and career might be spent for taking care of these guys mistakes,careless. Tester/QA is responsible for the product, not for careleass.Yes, your are finding bugs, but what behind these bugs are careless and irresponsibility. You need to fix careless and irresponsibility though it is tough, so be tough. When a production bug occurred, no one will stand in your side.So you need to exposure the facts, I mean real facts, where these bugs? and Why so many bugs, then you can push to reduce bugs, and push DEV moving forward, otherwise every dirty work will on your shoulder. Does DEV not know Unit test can help quality? They know, Does DEV not know they should tell you a little bit more what a requirement is, because they know you don’t invloved at all in first place? They know, explaination is not a techinical work, in their option, it is not worth to do, that’s it. So just tell the dev/dev manager what you want, what the result right now, what is good and what is bad, they will learn from that. Dev Manager love to see feedback. Only thingneed to pay attention might be the reporting skill, and how to handle conflict. Be a maid is no future in tech world, no one really care about what the careless is, they care about the careless issue should be never happened. You can’t only spend time for others careless, you need to fix it for the root cause.Good Luck, and we tester have long way to go, be tough! Show the Data,MetricsShow the data, metrics is good to be professional, and just focus on the thing your team are talked about, not finger point. It can help you be tough and reasonable.But What kind data you can show? It is a question, and also hard to implement. Based on my experience, data like: How many Bugs in a sprint? How the bugs distributed? How a typical bug impact the whole process? What the turn around time for the bug or an iteration? It is hard to collect data, but it is still worth to collect some of them.","categories":[],"tags":[]},{"title":"","slug":"api-testing/3-InteljIdea-codecoverage","date":"2019-06-27T07:41:42.424Z","updated":"2019-06-27T07:41:42.424Z","comments":true,"path":"2019/06/27/api-testing/3-InteljIdea-codecoverage/","link":"","permalink":"http:/2019/06/27/api-testing/3-InteljIdea-codecoverage/","excerpt":"","text":"Using IntelljIdea For Code CoverageTwo Steps: Run Test Code with code coverage - Right click the test class, select run *** with code coverage Check the Code Coverage in intelli idea Line Code Covearge/Method Coverage Read marked as not covered lines, green as covered lines","categories":[],"tags":[]},{"title":"","slug":"api-testing/4-Productivity-SimpleMock","date":"2019-06-27T07:41:42.424Z","updated":"2019-06-27T07:41:42.429Z","comments":true,"path":"2019/06/27/api-testing/4-Productivity-SimpleMock/","link":"","permalink":"http:/2019/06/27/api-testing/4-Productivity-SimpleMock/","excerpt":"","text":"The Easiest Mock, The highest ROIActually it is not about how to test Rule Based Risk Engine, it is about how to use simple codes to improve thedaily productivities. The Risk Engine is in the middle of the whole system, The upstream and downstream modules leveragethe result of the Risk Engine by API call in their own business flow. When other modules’s tester want to execute their test cases,they often wanted to get the different risk engine results on demand. That means I needed to support them for their casesas I am the owner of risk engine. Everyday, I was interrupted serveral times. It really bothered me a lot. I can’t refuse, butneed to find a solution. Then the easiest mock came. Mock- Get What You Set!It is quite simple but it is worth to write because it represents the value of codes which a tester can implement. I implemented a new WebService in our repo, and used a Map to store what the client set for mockingpurpose. Then next API call against the setting URL, the response is what the client Set even without any deployment or restart. How can I achieve this? The most important thing is that we used the configuration center - Apollo. But does this mean in real case? You never need to restart the server for changing application properties. It makes things easier. The whole process was that: Setup Mock by calling: 123456789101112131415161718192021222324252. Change the Risk Engine Url to ```http://domain/mock/A/getMock``` in Apollo Portal 3. Deploy the changes4. Other modules&apos; QA now can control the Risk Engine Response for any cases. And even more, this actually can be applied to any other Http service to decouple modules,free my time, and keep me focusingHere is the simple codes.It only takes 10 minutes to complete, but it saved me a lot of time in daily basis.- GenericMockStore for store Mock```java@Component@Profile(&quot;test&quot;)public class GenericMockMemStore &#123; private ConcurrentHashMap&lt;String, Object&gt; mockStore = new ConcurrentHashMap&lt;&gt;(); public void saveMock(String key, Object value) &#123; this.mockStore.put(key, value); &#125; public Object getMock(String key) &#123; return this.mockStore.get(key); &#125;&#125; GenericMock Service 1234567891011121314151617181920212223242526@RestController@RequestMapping(\"/mock\")@Profile(\"test\")public class GenericMockController &#123; @Autowired private GenericMockMemStore mockMemStore; @RequestMapping(\"/&#123;productName&#125;/setup\") @PostMapping public MockSetupResponse setupMock(@RequestBody GenericMockResponse setupResponse, @PathVariable String productName, HttpServletRequest request)&#123; mockMemStore.saveMock(productName,setupResponse); return MockSetupResponse.success(); &#125; @RequestMapping(value = \"/&#123;productName&#125;/getMock\",method = &#123;RequestMethod.GET, RequestMethod.POST,RequestMethod.PUT&#125;) public Object getMock(@PathVariable String productName, HttpServletRequest request)&#123; return mockMemStore.getMock(productName); &#125;&#125; Here is an explaination for these codes: Two APIs: POST /mock/{productName}/setup for setup mock for the productName you set /mock/{productName}/getMock get the mock reponse which set previously GenericMockMemStore: Store the mocks by key: productName in memory Like I said before, the automation testing is not about automation, but about writing codes for testing,and productivity.Automation is a conception, not an action. It is too big to accomplish. But Writing codes is actionable, and you can see whatyou accomplished and what you improved immediately. And also know the infrastructure more, you will find the solution is in the upstream or low level.This is a tip I used when I tested this project. Luckly it worked. But still it is not a perfect solution, there are qeustions over here: Is there any pain point to improve? How to make it happen? Don’t write any code, use exisitng tools like YAPI, can we achieve the same? Maybe you can find your answer, or stay tuned, I will write a post later. Finally It is honor to make these codes in the develop official repos.","categories":[],"tags":[]},{"title":"","slug":"api-testing/1-Demo-TestCase","date":"2019-06-27T07:41:42.413Z","updated":"2019-06-27T07:41:42.418Z","comments":true,"path":"2019/06/27/api-testing/1-Demo-TestCase/","link":"","permalink":"http:/2019/06/27/api-testing/1-Demo-TestCase/","excerpt":"","text":"Integration-Runner Test Case DemoLast chapter introduce how to build a test framework in two days,In this chapter, let’s do demos: A Api TestCase Api Chain Test Case Pre-Condition And Verification Render to use context data A Api TestCaseHere are two cases: after call HttpBin API, check the url field in response is http://httpbin.org 1\"verification\": &#123;\"url\": \"is_equal_to http://httpbin.org\"&#125; after call HttpBin API, check the headers.Accept field in response is application/json1 The overall cases is: 12345678910111213141516171819202122232425262728&#123; \"test_cases\": [&#123; \"name\": \"getapi-tc-1\", \"tc_id\": \"tc-get-1\", \"steps\": [ &#123; \"name\": \"http get api\", \"precondition\": &#123;&#125;, \"service\": HttpBinGet, \"params\": &#123;&#125;, \"verification\": &#123;\"url\": \"is_equal_to http://httpbin.org\"&#125; &#125; ]&#125; ,&#123; \"name\": \"getapi-tc-21\", \"tc_id\": \"tc-get-2\", \"steps\": [ &#123; \"name\": \"http get api\", \"precondition\": &#123;&#125;, \"service\": HttpBinGet, \"params\": &#123;&#125;, \"verification\": &#123;\"headers.Accept\": \"is_equal_to application/json1\"&#125; &#125; ]&#125; ]&#125; and the demo codes are: 12345678@allure.epic(\"testing http bin test cases\")class TestHttpBinTestCase: @allure.feature(\"testing http bin get\") def test_httpbin_get(self): runner = IntegrationExecutor(httpbinget_testcases) result = runner.run() assert result.get_tc_result() == \"pass\" Api Chain Test Casetest cases: 123456789101112131415161718192021222324&#123; \"test_cases\": [&#123; \"name\": \"tc description\", \"tc_id\": \"testCaseId\", \"steps\": [ &#123; \"name\": \"http get api\", \"precondition\": &#123;&#125;, \"service\": HttpBinGet, \"params\": &#123;&#125;, \"post_action\": &#123;\"url\": \"url\", \"args\": \"args\"&#125;, \"verification\": &#123;\"url\": \"is_equal_to http://httpbin.org\"&#125; &#125;, &#123; \"name\": \"http post api\", \"precondition\": &#123;&#125;, \"service\": HttpBinPOST, \"params\": &#123;&#125;, \"post_action\": &#123;&#125;, \"verification\": &#123;\"url\": \"is_equal_to http://httpbin.org\"&#125; &#125; ] &#125;]&#125; 12345678@allure.epic(\"testing http bin test cases\")class TestHttpBinTestCase: @allure.feature(\"testing http bin get/post\") def test_httpbin_tc(self): runner = IntegrationExecutor(httpbin_testcases) result = runner.run() assert result.get_tc_result() == \"pass\" the test cases code is almost same. Pre-Condition And Verification Render to use context dataThis case is more complex, use pre-condition, post-action, and verficiation to checkouthow the context processing. We have two Api: /json api to get a json, in this api’s response, there is a author field,value is “Yours Truly” /cookies/set api is to query a value by query parameter freeform So assume there is a workflow in real business: call /json to get author then use the author name to query(call /cookie./set) some author properties The author name might be changed over time in different environment, so I have to callthe api first in step 1, then getting the author name as the second api’s input, finally call the secondapi then verify the result . So the example test cases is: Case 1: Use Context and Render Input and Verifications Case2: Use jinja2 built-in filter to handle parameters in test cases and again, there is no re-invention, just use the exiting jinja2 template Detail please find the the codes in github","categories":[],"tags":[]},{"title":"","slug":"api-testing/0-start-from-the-end","date":"2019-06-27T07:41:42.404Z","updated":"2019-06-27T07:41:42.413Z","comments":true,"path":"2019/06/27/api-testing/0-start-from-the-end/","link":"","permalink":"http:/2019/06/27/api-testing/0-start-from-the-end/","excerpt":"","text":"Implement A Integration Libs in two daysThere is a question over my head several times. is it real hard for tester to write test codes?I don’t know, but I just want to do a task to evaluate this conclusion. Start From The EndI don’t prefer the term automation testing, but like the term write testing codes.Automation testing is almost defined as failure in most of testers’s mind(not company, company still think it is valuable).As I known, many testers(a big portion actually) just think automation testing is a political job which actually has no value at all in reality.Most of the automation cases are never used after it passed one time.Almost in every testing meet-up, there is always someone talked about test platform,how good it is,how easy to use.But in reality,almost every test platform user complained the test platform is to hard to use. Why? and what’s the gap between those platform andtheir users. I don’t know. But I just believe automation testing will never happen if you never write codes, only doing configuration like coding.Write scripts should be a basic skill for tester, like eating or drinking. And in other hands, setting a high expectation in a short period of time which is way beyond the average tester’s coding skill.There are too much legacy debit out there. High expectation meets even high debit, it can easily crash you.The delayed schedule, the unreachable target, and voices like automation testing doesn’t work is just around you.Finally, you will find out automation never from nowhere, it happened when you write codes line by line just.And if you re-think about automation, it is quite reasonable. It is just like a product which want to automate business flow. The product is built bytons of codes. So does automation testing. And also to pay back the debit, accumulate codes in daily basis in the key. Don’t expected to pay back itin a short time, just focus accumulating the tests day in and day out, then someday, you will feel a little easy. Back to the topic, What the task is given to myself is that: Write A Simple Integration Libs as a tiny testing framework(just work) in 2-3 days Leverage Existing Libs as more as possible, and don’t write too much complex codes Integration library, not a http library. It is open for different component client The test codes could be used in any other place,but not only for testing Not strict, different coding level can use and ramp up Let’s getting startThink about integration testing(not consider UI), it is actually calling different service or api, then get a result to verify. And if in more complex workflow, it looks like a workflow or api call chain So I need to abstract these into following conception: Executor: execute the who process no matter how many steps the test case should have Client: every api/service invoker is a client, no matter http,redis,database or whatever tester used in dailybasis for send a request to get a response Validator: verify the result TestCase: test cases with test case data and steps Executor - Integration ExecutorIntegration Executor is used to run the whole test case, and it is the coreof this tiny lib, it targets to connect all the things used when testing. Before implement it, make the code structure first, it is quite clean and easy to understand Let’s do following things to implement it: define the test case data structure implement a generic client implement a extractor to extract data from response implement a validator to validate result implement a context to store and calculate runtime data when execute test cases ClientThe client implement is for generic purpose, so I just define a callable objector with a invoke method: 12345678910111213141516171819202122232425class Client: def __init__(self, params, env): self.params = params self.env = env def invoke(self): \"\"\" what ever :return: ClientResponse \"\"\" raise NotImplementedError(\"abstract class, need an implementation\") def __call__(self, *args, **kwargs): print(\"client should a callable object or with a invoke method\") return self.invoke()``` and the response for a client also need to be unified and generic:```pythonclass ClientResponse(): def __init__(self, response): pass So basically I defined a generic client which the input is : input test data12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273742. ```env```: target environmentOutput is:```ClientReponse```: Generic Output Object, which have a status code and response data, data should be in json or dict which is easy to handle A http client is implement based on python ```requests``` lib.```pythonhttp_methods = &#123; &quot;get&quot;: requests.get, &quot;post&quot;: requests.post, &quot;delete&quot;: requests.delete, &quot;put&quot;: requests.put, &quot;option&quot;: requests.options&#125;class HttpClient(Client): req_url = &quot;&quot; domain = &quot;&quot; headers = &#123; &quot;accept&quot;: &quot;application/json&quot;, &quot;content-type&quot;: &quot;application/json&quot; &#125; req_body = &#123;&#125; ## make sure the some variables with default values query_params = [] method = &quot;post&quot; def __init__(self, params, env): super().__init__(params, env) def invoke(self): real_req_url = self.__build_request_url() self.__build_header() self.__build_body() http_method = http_methods.get(self.method.lower(), requests.get) response = http_method(url=real_req_url, headers=self.headers, data=self.req_body) return make_client_response(response) def __build_request_url(self): if self.env.get_config_by_key(self.domain) is None: raise ClientException(&quot;domain name should be set in environment or config file&quot;) else: url = self.env.get_config_by_key(self.domain) real_req_url = url + self.__make_request_path() + self.__make_query_url() return real_req_url def __build_header(self): if self.params.get(&quot;headers&quot;, &quot;&quot;) != &quot;&quot;: for h_name, h_value in self.params.get(&quot;headers&quot;).items(): self.headers.update(&#123;h_name: h_value&#125;) def __make_request_path(self): self.req_url = self.req_url.format(**self.params) return self.req_url ## todo: set value in a dict,use path def __build_body(self): for param_name, param_value in self.params.items(): kv_util.set_value(self.req_body, param_name, param_value) def __make_query_url(self): query_url = &quot;&quot; if len(self.query_params) &gt; 0: query_url = query_url + &quot;?&quot; # query_temp =&quot;%s=%s&amp;&quot; for query_param in self.query_params: if self.params.get(query_param, &quot;&quot;) != &quot;&quot;: query_url = query_url + query_param + &quot;=&quot; + self.params.get(query_param, &quot;&quot;) + &quot;&amp;&quot; return query_url Don’t invent any new thing, just use requests Extractor First of all, why I need an extractor? The extractor is used to get a value from a json or dict by an expression like jsonpath. So that we can leverage this tiny tool to get any value in response. The demo: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051simple_dict_json = &#123; \"characters\": &#123; \"Lonestar\": &#123; \"id\": 55923, \"role\": \"renegade\", \"items\": [ \"space winnebago\", \"leather jacket\" ] &#125;, \"Barfolomew\": &#123; \"id\": 55924, \"role\": \"mawg\", \"items\": [ \"peanut butter jar\", \"waggy tail\" ] &#125;, \"Dark Helmet\": &#123; \"id\": 99999, \"role\": \"Good is dumb\", \"items\": [ \"Shwartz\", \"helmet\" ] &#125;, \"Skroob\": &#123; \"id\": 12345, \"role\": \"Spaceballs CEO\", \"items\": [ \"luggage\" ] &#125; &#125;&#125;# encoding: utf-8class TestDataExtractor: def test_list_get_value_by_exp(self): result = data_extractor.get_value_by_exp(simple_dict_json, \"characters\") assert len(result) &gt;= 1 def test_get_value_by_exp(self): result = data_extractor.get_value_by_exp(simple_dict_json, \"characters.Lonestar.items[0]\") assert result == \"space winnebago\" def test_get_value_by_exp_not_exist(self): result = data_extractor.get_value_by_exp(simple_dict_json, \"characters.Lonestar323.items[0]\") assert result == \"space winnebago\" just give a path expression, then get the value without going to a json level by level. Don’t invent new thing: the implementation is relied on following lib: jmespath dictor ValidatorValidator is used to validate if an actually result meets the expected result. Also, refer to the assertPy, I did a function to validate result: The Demo: 123456class TestValidator(): def test_demos(self): result = validator.validate(\"value\",\"is_equal_to test\") assert result[0],\"fail\" print(str(result[1])) Test CaseTest Case is to connect all these things to feed into Integration Runner The Basic Schema is : 123456789101112131415161718192021222324 &#123; \"test_cases\": [&#123; \"name\": \"tc description\", \"tc_id\": \"testCaseId\", \"steps\": [ &#123; \"name\": \"http get api\", \"precondition\": &#123;&#125;, \"service\": HttpBinGet, \"params\": &#123;&#125;, \"post_action\": &#123;\"url\": \"url\", \"args\": \"args\"&#125;, \"verification\": &#123;\"url\": \"is_equal_to http://httpbin.org\"&#125; &#125;, &#123; \"name\": \"http post api\", \"precondition\": &#123;&#125;, \"service\": HttpBinPOST, \"params\": &#123;\"url\": \"&#123;&#123;args&#125;&#125;\"&#125;, \"post_action\": &#123;&#125;, \"verification\": &#123;\"url\": \"is_equal_to http://httpbin.org\", \"json\": \"is_none\"&#125; &#125; ] &#125;]&#125; The schema is easy to understand. The is for a Python Object, here1234567891011121314HttpBinGet is an api for call HttpBinGet service, and the service is also easy to implement.```pythonclass HttpBinGet(HttpClient): req_url = &quot;/get&quot; domain = &quot;domain&quot; headers = &#123; &quot;accept&quot;: &quot;application/json&quot;, &quot;content-type&quot;: &quot;application/json&quot; &#125; req_body = &#123;&#125; ## make sure the some variables with default values query_params = [] method = &quot;GET&quot; ContextContext is used for store and calculate data. It will be used in executorin process pre-condition and post action to handler. What data context stored in key-value manner, for example: in test case data: 1\"post_action\": &#123;\"url1\": \"url\", \"args1\": \"args\"&#125; the post action processor will put url1 as key, the value is the value extractedby the path “url” from response and also, the context will used to render data in process pre-condition,because some input data is in generated in runtime: 1\"params\": &#123;\"url\": \"&#123;&#123;args&#125;&#125;\"&#125; will be replaced by a value which is from response before. Use python template lib jinja2 can achieve it. Revisit ExecutorNow every tiny thing is ready for Executor. And everything is ready. For Detail please refer the demo.","categories":[],"tags":[]},{"title":"Rule Based Risk Engine Part 3 - The Easiest Mock, The highest ROI","slug":"api-testing/CreditRisk-Testing-3","date":"2019-04-28T15:58:45.000Z","updated":"2019-07-29T04:16:23.972Z","comments":true,"path":"2019/04/28/api-testing/CreditRisk-Testing-3/","link":"","permalink":"http:/2019/04/28/api-testing/CreditRisk-Testing-3/","excerpt":"","text":"Rule Based Risk Engine Part 3 - The Easiest Mock, The highest ROIActually it is not about how to test Rule Based Risk Engine, it is about how to use simple codes to improve thedaily productivities. The Risk Engine is in the middle of the whole system, The upstream and downstream modules leveragethe result of the Risk Engine by API call in their own business flow. When other modules’s tester want to execute their test cases,they often wanted to get the different risk engine results on demand. That means I needed to support them for their casesas I am the owner of risk engine. Everyday, I was interrupted serveral times. It really bothered me a lot. I can’t refuse, butneed to find a solution. Then the easiest mock came. Mock- Get What You Set!It is quite simple but it is worth to write because it represents the value of codes which a tester can implement. I implemented a new WebService in our repo, and used a Map to store what the client set for mockingpurpose. Then next API call against the setting URL, the response is what the client Set even without any deployment or restart. How can I achieve this? The most important thing is that we used the configuration center - Apollo. But does this mean in real case? You never need to restart the server for changing application properties. It makes things easier. The whole process was that: Setup Mock by calling: 123456789101112131415161718192021222324252. Change the Risk Engine Url to ```http://domain/mock/A/getMock``` in Apollo Portal 3. Deploy the changes4. Other modules&apos; QA now can control the Risk Engine Response for any cases. And even more, this actually can be applied to any other Http service to decouple modules,free my time, and keep me focusingHere is the simple codes.It only takes 10 minutes to complete, but it saved me a lot of time in daily basis.- GenericMockStore for store Mock```java@Component@Profile(&quot;test&quot;)public class GenericMockMemStore &#123; private ConcurrentHashMap&lt;String, Object&gt; mockStore = new ConcurrentHashMap&lt;&gt;(); public void saveMock(String key, Object value) &#123; this.mockStore.put(key, value); &#125; public Object getMock(String key) &#123; return this.mockStore.get(key); &#125;&#125; GenericMock Service 1234567891011121314151617181920212223242526@RestController@RequestMapping(\"/mock\")@Profile(\"test\")public class GenericMockController &#123; @Autowire private GenericMockMemStore mockMemStore; @RequestMapping(\"/&#123;productName&#125;/setup\") @PostMapping public MockSetupResponse setupMock(@RequestBody GenericMockResponse setupResponse, @PathVariable String productName, HttpServletRequest request)&#123; mockMemStore.saveMock(productName,setupResponse); return MockSetupResponse.success(); &#125; @RequestMapping(value = \"/&#123;productName&#125;/getMock\",method = &#123;RequestMethod.GET, RequestMethod.POST,RequestMethod.PUT&#125;) public Object getMock(@PathVariable String productName, HttpServletRequest request)&#123; return mockMemStore.getMock(productName); &#125;&#125; Here is an explaination for these codes: Two APIs: POST /mock/{productName}/setup for setup mock for the productName you set /mock/{productName}/getMock get the mock reponse which set previously GenericMockMemStore: Store the mocks by key: productName in memory Like I said before, the automation testing is not about automation, but about writing codes for testing,and productivity.Automation is a conception, not an action. It is too big to accomplish. But Writing codes is actionable, and you can see whatyou accomplished and what you improved immediately. And also know the infrastructure more, you will find the solution is in the upstream or low level.This is a tip I used when I tested this project. Luckly it worked. But still it is not a perfect solution, there are qeustions over here: Is there any pain point to improve? How to make it happen? Don’t write any code, use exisitng tools like YAPI, can we achieve the same? Maybe you can find your answer, or stay tuned, I will write a post later. Finally It is honor to make these codes in the develop official repos.","categories":[],"tags":[{"name":"real","slug":"real","permalink":"http:/tags/real/"},{"name":"think-different","slug":"think-different","permalink":"http:/tags/think-different/"},{"name":"productivity","slug":"productivity","permalink":"http:/tags/productivity/"}]},{"title":"Think in Testing 1-Be Tough","slug":"real/Thoughts-Be-A-Touch-Tester","date":"2019-04-28T15:58:45.000Z","updated":"2019-07-29T04:18:28.358Z","comments":true,"path":"2019/04/28/real/Thoughts-Be-A-Touch-Tester/","link":"","permalink":"http:/2019/04/28/real/Thoughts-Be-A-Touch-Tester/","excerpt":"","text":"Think in Testing 1: Be ToughIf someone tell you that software testing or quality assurance is an easy job to do, he/she might not understand what a tester or qa do. There are many perspective a tester or qa involved: Testing Requirement Clarification Dev Process/Release Process Planning Almost every phase QA is involved, it can burn you out easily. Here I just want to talk about some bad thing might happed, and why be tough is a basic charactor of a QA or Tester. Don’t Be a maidDon’t be a maid, and don’t spend too much time on other’s careless and irresponsibility.Need to fix it. In many Chinese domestic company, Tester and QA is a maid of Developer, everything could be in testing scope. Let me summarize several common cases: Some incomplete task, need to test Some codes never work, neet to test Some bug can’t be produced, need to test Some performance issues can’t be measured, need to test What ever the requirement is, no matter you tester invovled or not, send it to test And more important thing is that normally a tester/qa might face 5+ developers. If you can not be tough to Dev, your time and career might be spent for taking care of these guys mistakes,careless. Tester/QA is responsible for the product, not for careleass.Yes, your are finding bugs, but what behind these bugs are careless and irresponsibility. You need to fix careless and irresponsibility though it is tough, so be tough. When a production bug occurred, no one will stand in your side.So you need to exposure the facts, I mean real facts, where these bugs? and Why so many bugs, then you can push to reduce bugs, and push DEV moving forward, otherwise every dirty work will on your shoulder. Does DEV not know Unit test can help quality? They know, Does DEV not know they should tell you a little bit more what a requirement is, because they know you don’t invloved at all in first place? They know, explaination is not a techinical work, in their option, it is not worth to do, that’s it. So just tell the dev/dev manager what you want, what the result right now, what is good and what is bad, they will learn from that. Dev Manager love to see feedback. Only thingneed to pay attention might be the reporting skill, and how to handle conflict. Be a maid is no future in tech world, no one really care about what the careless is, they care about the careless issue should be never happened. You can’t only spend time for others careless, you need to fix it for the root cause.Good Luck, and we tester have long way to go, be tough! Show the Data,MetricsShow the data, metrics is good to be professional, and just focus on the thing your team are talked about, not finger point. It can help you be tough and reasonable.But What kind data you can show? It is a question, and also hard to implement. Based on my experience, data like: How many Bugs in a sprint? How the bugs distributed? How a typical bug impact the whole process? What the turn around time for the bug or an iteration? It is hard to collect data, but it is still worth to collect some of them.","categories":[],"tags":[{"name":"real","slug":"real","permalink":"http:/tags/real/"},{"name":"think-different","slug":"think-different","permalink":"http:/tags/think-different/"},{"name":"productivity","slug":"productivity","permalink":"http:/tags/productivity/"},{"name":"ThinkInTesting","slug":"ThinkInTesting","permalink":"http:/tags/ThinkInTesting/"}]},{"title":"Rule Based Risk Engine Part 2 - Write Code to Test","slug":"api-testing/CreditRisk-Testing-2","date":"2019-04-25T15:58:45.000Z","updated":"2019-07-29T04:16:45.453Z","comments":true,"path":"2019/04/25/api-testing/CreditRisk-Testing-2/","link":"","permalink":"http:/2019/04/25/api-testing/CreditRisk-Testing-2/","excerpt":"","text":"Rule Based Risk Engine Part 2 - Write Code to TestWhat to do is quite obvious: Compose input data - Test Case Input Fundamental Data Third Party And in-house data Mock the third party and in-house data according test cases Call the Evaluation API to checkout if meet the expectation And how to write code? I separate into different modules: TestCaseLoader: load the whole input parameters DataFactory: Produce different Data as input parameters RiskInputDataFactory MockDataFactory Some Auto Generated Data Helper for testing purposes Clients: invoke evaluation api and mock service api RiskEvaluationClient MockClient Third Party and In-house Data Feature Manager Feature Manager Test Case Runner TestCase Runner Template Implement The different Modules - TestCaseLoaderTestCaseLoader, levarage easy-poi, it helps you to read/write excelvery quickly. For how to use easy-poi, please refer easy-poi Implement The different Modules - DatafactoryAll about handle data, so need some utility class, IdCard Generator Generate IDCard through age Generate several ids, like request id Generate Times, such as creditTime So I just write all these utilities, they are in Implement The different Modules - MockDataFactoryIt is very hard at the beginning, because there is not place to indicate there third party and in-house data name, and also there is big amount of these features. Finally I just find out that leverage Dev’s codes is the bese option. Do a quick change, and use Spring Class Scanner function do helo me a lot to achieve to mange the third part and in-houce data. Implement The different Modules - ClientsIt is quite simple, just leverage the Okwrap client. Implement The different Modules - TestRunnerTestRunnerTemplate Before Run After","categories":[],"tags":[{"name":"patterns","slug":"patterns","permalink":"http:/tags/patterns/"},{"name":"testing","slug":"testing","permalink":"http:/tags/testing/"},{"name":"API Testing","slug":"API-Testing","permalink":"http:/tags/API-Testing/"},{"name":"real","slug":"real","permalink":"http:/tags/real/"}]},{"title":"Rule Based Risk Engine Testing Part 1- Background","slug":"api-testing/CreditRisk-Testing-1","date":"2019-04-23T15:58:45.000Z","updated":"2019-07-29T04:16:23.971Z","comments":true,"path":"2019/04/23/api-testing/CreditRisk-Testing-1/","link":"","permalink":"http:/2019/04/23/api-testing/CreditRisk-Testing-1/","excerpt":"","text":"Rule Based Risk Engine Testing Part 1- BackgroundThis article introduces a real world case for testing a rule based risk engine. Let me separate it into several parts: System Overview to introduct the rule based risk engine Typical Cases Automate the test cases, and how ? 1. Rule Based Risk Engine System OverviewThis is my fist risk engine project. I am not sure how other risk engine does,just try to introduce what I experienced, and what I had found. Let’s start with what this module does. In short, this risk engine provides a capability to rate a loan applicant from whethere he/she is eligible for a loan to how much he/she can borrow. So There are two major results: is eligible? And what the score/credit amount/terms for this applicant And there are different products to apply, so the rule and rating system should be configurable. There are rule engine,scorecard and decision tree components to meet the configuration needs. The whole workflow is like this: The whole system is a decision flow, which includesanti-fraud rules, score-card for rating and decision tree to make a decision. If you wanto unify it, it is a decision flow, which composed by rules and decision trees. 1.1 A short introduction for Rule EngineRule Engine article from Martin Flow, it abstracts rule engine into three conceptions: Condition Action Chain Basically A rule includes conditons and actions, and the chain composites these rules’ conditions and actions by a runtime context. An example in this blog for explaination: 1234if car.owner.hasCellPhone then premium += 100;if car.model.theftRating &gt; 4 then premium += 200;if car.owner.livesInDodgyArea &amp;&amp; car.model.theftRating &gt; 2 then premium += 300; is condition, and ```then``` is action, one ```rule```12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970is composed by one ```if``` and one ```then```. And the chain is composed by different rules. Obviously the ```premium``` should be in the chain context in this case, because it passed through the whole rule sets.Quite simple and easy to understand.The single rule is simple enough, so the testing might be undervalued. Think about if there are hundrends rules out there, test and understand the whole picture might be not easy compared with a single rule. This is what Martin Flow claimed, and also he worried about the implicit rule and context in the rule engine module.The Rule Risk Engine I meet was simillar to what mentioned in this blog. The difference is that it has wight point for socre card and decision tree modules. In this system, a rule is A node which contains:1. Expressions for evaluating an input data2. A Weight for a rule3. Composite Rule for Weight Point to make different disicion4. Also this Node points a true or false path to go different evaluation pathWhat ever these nodes contain, just think about it is a chain or composite rule. Here is a simple case to demostrate how the system works:![img](https://raw.githubusercontent.com/evenhumble/hustle-player/master/img/DecisionFlow.jpg)The output is a score. A score represents how much could be borrowed in a loan system. In this simple case, the age might be a implicit feature which should be fetched by internal api based on fundamental data like IDCard Number or SSN Number. And the rules and score card rules are pre-defined(So it is ruled based system).So you can understand the whole module in this way:1. Featch all relative data for the rules based on the fundamental information, these relative data need to be mocked because I can&apos;t control what third party api returned, while tests need to controll what the thrid party api should return as an input variable.2. Go through all the rule nodes, evaluate the result and the score to get a conclusion which indicates eliable for a loan, and how much could be borrowed.So the modules should aim at how to fetch the data(facts) , and how to go through the rule engine to calculate a score. And so does this module. ### 1.2 Rule Based Risk Engine ComponentsHere are components:![img](https://raw.githubusercontent.com/evenhumble/hustle-player/master/img/risk-flow-2.jpg)There are many different tech stack used, such as elastic search, mongodb, hbase, redis,spring boot, rule engine,etc. It is hard to test in my first impression, not only it is complex, but also I only had one week to understand the whole system, and I am the only person who is responsoible for testing, meanwhile there are actual 7 developers out there.Learn it,separate the concerns, and then check out what these components really do:- ***Third Party Service*** : Fetch Data,it calls different third party services to get some risk relative values like what the income level of an applicant, is there any loans, is there any overdue during the past one year,etc. Then provide these data to rule engine as facts(so called risk features)- ***Data Aggeragation Service***: Fetch Data from in-house data warehouse,aggeragating in house data to provide to rule engine as facts/risk features- ***Data Collection Service***: Fetch Data,simillar too, collect different in house data to provide to rule engin as facts/risk features- ***Rule Engine***: Rules Engine,process the risk evaluation to figure out eligable result and risk rating result- ***Rule Tracing***: supplement component, tracing every rule evalution result for debug to error diagose- ***Risk Evaluation Store***: supplement component,store rule evealution result- ***rule tracing, risk result store***, these are supplement components, they may be important later but not now because this is a rule engine system for a startup department, just starting to accomulate the risk dataAfter dive into these components a little bit, It is easy to find out that the key critical component is the Rule engine in current stage which shoule be absolutely the priority. Other components are more like data collector/feeder or result recorder. They should be important if the volumn of users increased,or more features need to be produced. But on current stage,it is just a MVP product which try to validate if the idea is feasible.The more things need to do, the more I need to focus a critical componet. So I focused the Rule Engine first.### 1.3 Rule Engine Typical CasesThe rule engine typical cases is that:![img](https://raw.githubusercontent.com/evenhumble/hustle-player/master//img/RiskEventFlow.jpg)The things turn out that, rule engine accepts income risk input, and leverage all the different data from third party/data collection/data aggeragation services, then output the risk rating.Let me summary it in a tester point view, rule engine&apos;s input is different data, and the output is the data calculated by the rules. If the rule composed by rules,and decision tree, the test cases covered all the node and path, then it is good to go. ### 1.4 Test ItLet&apos;s see a test case first:Test Case Input:```json&#123; &quot;riskFeatures&quot;: &#123; &quot;idNumber&quot;: &quot;610304199801120878&quot;, &quot;levelType&quot;: &quot;10&quot;, &quot;flowNo&quot;: &quot;1506&quot;, &quot;applicationId&quot;: &quot;ac8e120c-3615-4bdb-a92d-a118e24e33da&quot; &#125;&#125; I can change the levelType to different value, then send to risk evaluation api to get different result.And this is typical test cases design. Testing a Rule steps: change the risk input date call risk evaluation api get result and check the result It looks very easy. The problem is how many these kind of parameters are? In a real case, normally 50+ parameters need to change because the third party data are aslo the input of rule engine which I can’t control it only mock it as input implicit parameters. So it is going to be crazy if create and maintain these test cases manually. There third part data is like: The best case for 50 parameters test cases design, every parameters has 3 possible values, then at least there are 150 cases(doesn’t consider the combination). Manual testing is not a option under this condition if the business need to complete all the testing in one day, also it will burn me out if do these testing more than one time. So the only option is to write code to test(I don’t like the term automation testing, I prefer the term write codes for testing). Let’s start coding. Coding is not rocket science, don’t be afraid of it especially for testers. In next article, how to implement the test code will be introduced. It is not that hard but improve the productivity significantly. One more point is that it might be more interesting than do it manually in this case.","categories":[],"tags":[{"name":"patterns","slug":"patterns","permalink":"http:/tags/patterns/"},{"name":"testing","slug":"testing","permalink":"http:/tags/testing/"},{"name":"API Testing","slug":"API-Testing","permalink":"http:/tags/API-Testing/"},{"name":"real","slug":"real","permalink":"http:/tags/real/"}]},{"title":"Git Sub Module Usage","slug":"0-GIT-SUBMODULE","date":"2019-04-20T15:58:45.000Z","updated":"2019-07-29T04:15:46.858Z","comments":true,"path":"2019/04/20/0-GIT-SUBMODULE/","link":"","permalink":"http:/2019/04/20/0-GIT-SUBMODULE/","excerpt":"","text":"Git Sub Module UsageA Git Repo sometimes has several sub projects which are also a git repo. Let’s walk through following scenarios to became a supergit sub module user. The Scenario are: Add Git Sub odule into a existing Git Repo Git Clone With Sub Modules Push To Sub Module’s remote repo Add Git Sub Module into a existing Git RepoIt is a quit straight forward. You have already clone one git repo to local, then you want to add a sub module to this repo.So just using: 1git submodule add https://github.com/allroundtesters/Shell-Steps.git submodule add ``` is the command 123456to use. Just checkout the folder, everything is there. So easy, no magic. But what is different with ```git clone ```, The different is that ```.gitmodules``` file is added to the existing repo, and there sub module info is in it:```sh[submodule &quot;Shell-Steps&quot;] path = Shell-Steps url = https://github.com/allroundtesters/Shell-Steps.git Obviously, if you add more than one sub module, the sub module info will be appened into the file to make the parent repo know where the sub modules are.12345678910That&apos;s it.## Git Clone With Sub ModulesNormally you git clone one project, then find out several folders is empty, then you are confused what happened. Don&apos;t worry, use the following command to have a try:```shgit pull --recurse-submodules# or for git 1.8.2git submodule update --recursive --remote Then everything is ready. Go to work right now. Push To Sub Module’s remote repoThere is no difference. Go to the Sub Module Folder. Then use git push or change the working branch. Everything is same as the single git repo. T here are several advaned command for sub modules, your can read gitbook-submodules for more details.","categories":[],"tags":[{"name":"git","slug":"git","permalink":"http:/tags/git/"}]},{"title":"Use Anaconda3 Python In Ubuntue Usage","slug":"1-Add_Anaconda3_Python","date":"2019-04-20T15:58:45.000Z","updated":"2019-07-29T04:15:53.134Z","comments":true,"path":"2019/04/20/1-Add_Anaconda3_Python/","link":"","permalink":"http:/2019/04/20/1-Add_Anaconda3_Python/","excerpt":"","text":"Use Anaconda3 Python In UbuntuFirst of all, where is your annaconda3 installed, and where is the system python path? 12# anaconda3 path~/anaconda3/bin 1echo `whereis python` Then Add you anaconda3 to ~/.zshrc or ~/.bashrc PATH 12export ANACONDA_HOME=~/anaconda3export PATH=$ANACONDA_HOME/bin:$PATH","categories":[],"tags":[{"name":"python","slug":"python","permalink":"http:/tags/python/"},{"name":"annaconda3","slug":"annaconda3","permalink":"http:/tags/annaconda3/"}]},{"title":"Build API Testing Framework-1 - Learn Http Api","slug":"api-testing/APITesting-Intro","date":"2019-04-20T15:58:45.000Z","updated":"2019-07-29T04:16:18.332Z","comments":true,"path":"2019/04/20/api-testing/APITesting-Intro/","link":"","permalink":"http:/2019/04/20/api-testing/APITesting-Intro/","excerpt":"","text":"Build API Testing Framework-1 - Learn Http ApiAPI now, in most cases, it is a HTTP API which over http protocol. It is hard to explain without a example, so let’s start with a HelloWorld API sample.The main purposes of these apis are to do the CRUD(Create/Read/Update/Delete) against the resouce 1234567891011121314151617181920212223242526272829303132333435363738Here are HTTP Methods mapping to CRUD:|HTTP Method|CRUD|Resource|Response||-----------|----|--------|--------||GET|Read|/HelloWorld/&#123;id&#125;|200:success/404: not found||POST|Create|/HelloWorld|200:success/404: not found||Update|Update|/HelloWorld/&#123;id&#125;|200:success/404: not found||Delete|Delete|/HelloWorld/&#123;id&#125;|200:success/404: not found|It is easy to implement a sets of APIs against resource HelloWorld based on SpringBoot, here comes demo codes:```java@RestControllerpublic class HelloWorldController &#123; @GetMapping(&quot;/HelloWorld/&#123;id&#125;&quot;) public BaseResponse getHelloWorld(@PathVariable Long id) &#123; return BaseResponse.OK().data(HelloWorldDTO.builder().id(id).msg(&quot;Hello World&quot;).build()); &#125; @PostMapping(&quot;/HelloWorld&quot;) public BaseResponse&lt;HelloWorldDTO&gt; createHelloWorld(@RequestBody HelloWorldDTO requestBody) &#123; return BaseResponse.OK().data(requestBody); &#125; @PutMapping(&quot;/HelloWorld/&#123;id&#125;&quot;) public BaseResponse&lt;HelloWorldDTO&gt; updateHelloWorld(@PathVariable Long id, @RequestBody HelloWorldDTO updateData) &#123; return BaseResponse.OK().data(updateData); &#125; @DeleteMapping(&quot;/HelloWorld/&#123;id&#125;&quot;) public BaseResponse&lt;HelloWorldDTO&gt; deleteHelloWorld(@PathVariable Long id) &#123; return BaseResponse.OK().data(HelloWorldDTO.builder().id(id).msg(&quot;deleted!&quot;).build()); &#125;&#125; Start the web server, actaully there are 4 apis with different HTTP methods, GET/DELETE/POST/PUT, use postman to check what happened: It represents how the api work, and how to use postman to invoke the http api to get a result. So the api testing is simple, a client send a http request, then get the http response to check if the response is correct. In this case, if you want to start a api automation testing, what kind of codes need to write? In this case, it is very simple: A clint to invoke http api: Client Data builder to build input data: InputData Verify the response: OutputData the code example generated bu postman(java and OkHttpClient) is : 12345678910111213OkHttpClient client = new OkHttpClient();MediaType mediaType = MediaType.parse(\"application/json\");RequestBody body = RequestBody.create(mediaType, \"&#123;\\\"msg\\\":123&#125;\");Request request = new Request.Builder() .url(\"http://localhost:9090/HelloWorld\") .post(body) .addHeader(\"Content-Type\", \"application/json\") .addHeader(\"cache-control\", \"no-cache\") .addHeader(\"Postman-Token\", \"ac6e83d3-8446-4ae7-81ea-59316ca5cce7\") .build();Response response = client.newCall(request).execute(); Copy these codes, and run in maven project, your first API automation code is completed. By the way, there are several questions for HTTP API: What is Idempotent Methods? GET/HEAD/PUT/DELETE are declared idemponten What Option method used for? Is http api stateless? What does the stateless mean? All the information is in the request. In Next Chapter, let’s write code and go through these cases.","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http:/tags/java/"},{"name":"patterns","slug":"patterns","permalink":"http:/tags/patterns/"},{"name":"testing","slug":"testing","permalink":"http:/tags/testing/"},{"name":"API Testing","slug":"API-Testing","permalink":"http:/tags/API-Testing/"}]},{"title":"JAVA SimpleDateFormat Not ThreadSafe Python In Ubuntue Usage","slug":"2-SimpleDateFormat-Parse-Is-Not-ThreadSafe","date":"2019-02-20T15:58:45.000Z","updated":"2019-07-29T04:15:57.982Z","comments":true,"path":"2019/02/20/2-SimpleDateFormat-Parse-Is-Not-ThreadSafe/","link":"","permalink":"http:/2019/02/20/2-SimpleDateFormat-Parse-Is-Not-ThreadSafe/","excerpt":"","text":"JAVA SimpleDateFormat Not ThreadSafeSimpleDateFormat is not threadsafe, so when we use it in the a multiple threads environment, be careful. Follow is a JAVA class to demo the error: 12345678910111213141516171819202122232425262728public class SimpleDateFormatThreadUnsafetyExample &#123; private static SimpleDateFormat simpleDateFormat = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss\"); ## the evil here,it is not thread safe public static void main(String[] args) &#123; String dateStr = \"2018-06-22T10:00:00\"; ExecutorService executorService = Executors.newFixedThreadPool(10); Runnable task = () -&gt; parseDate(dateStr); for (int i = 0; i &lt; 100; i++) &#123; executorService.submit(task); &#125; executorService.shutdown(); &#125; private static void parseDate(String dateStr) &#123; try &#123; Date date = simpleDateFormat.parse(dateStr); System.out.println(\"Successfully Parsed Date \" + date); &#125; catch (ParseException e) &#123; System.out.println(\"ParseError \" + e.getMessage()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; Run it, let’s see what happeded?Following errors: 1234567891011121314151617181920212223242526272829303132java.lang.NumberFormatException: For input string: \"20182018E\" at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65) at java.lang.Long.parseLong(Long.java:589) at java.lang.Long.parseLong(Long.java:631) at java.text.DigitList.getLong(DigitList.java:195) at java.text.DecimalFormat.parse(DecimalFormat.java:2084) at java.text.SimpleDateFormat.subParse(SimpleDateFormat.java:1869) at java.text.SimpleDateFormat.parse(SimpleDateFormat.java:1514) at java.text.DateFormat.parse(DateFormat.java:364) at io.qkits.dailyissues.concurrence.SimpleDateFormatThreadUnsafetyExample.parseDate(SimpleDateFormatThreadUnsafetyExample.java:28) at io.qkits.dailyissues.concurrence.SimpleDateFormatThreadUnsafetyExample.lambda$main$0(SimpleDateFormatThreadUnsafetyExample.java:17) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)java.lang.NumberFormatException: multiple points at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:1890) at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110) at java.lang.Double.parseDouble(Double.java:538) at java.text.DigitList.getDouble(DigitList.java:169) at java.text.DecimalFormat.parse(DecimalFormat.java:2089) at java.text.SimpleDateFormat.subParse(SimpleDateFormat.java:2162) at java.text.SimpleDateFormat.parse(SimpleDateFormat.java:1514) at java.text.DateFormat.parse(DateFormat.java:364) at io.qkits.dailyissues.concurrence.SimpleDateFormatThreadUnsafetyExample.parseDate(SimpleDateFormatThreadUnsafetyExample.java:28) at io.qkits.dailyissues.concurrence.SimpleDateFormatThreadUnsafetyExample.lambda$main$0(SimpleDateFormatThreadUnsafetyExample.java:17) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) So move the SimpleDateFormat from static field to method level, it can solve this issue,or make the pareDate function sync. All the SimpleDateFormat method is not not thread safe?if I change the pareDate method as follow: 12345678910111213141516private static void parseDate(String dateStr) &#123; try &#123; Date date = simpleDateFormat.parse(dateStr); System.out.println(\"Successfully Parsed Date \" + date); &#125; catch (ParseException e) &#123; System.out.println(\"ParseError \" + e.getMessage()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; System.out.println(formatDate(new Date())); &#125; private static String formatDate(Date date)&#123; return simpleDateFormat.format(date); &#125; re-run it and even add more threads to run it, there is no error?Why and what happened? Need to dig it more deeper.","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http:/tags/java/"},{"name":"concurrent","slug":"concurrent","permalink":"http:/tags/concurrent/"}]},{"title":"Defensive Programming","slug":"real/3-Defensive-programing","date":"2019-02-20T15:58:45.000Z","updated":"2019-07-29T04:15:36.757Z","comments":true,"path":"2019/02/20/real/3-Defensive-programing/","link":"","permalink":"http:/2019/02/20/real/3-Defensive-programing/","excerpt":"","text":"Defensive Programming - reuse the validationWhat does Defensive Programming mean? Let’s look at some sampels: 123456789101112131415public class Report &#123; public void export(File file) &#123; if (file == null) &#123; throw new IllegalArgumentException( \"File is NULL; can't export.\" ); &#125; if (file.exists()) &#123; throw new IllegalArgumentException( \"File already exists.\" ); &#125; // Export the report to the file &#125;&#125; In this case, there are several validation for the input paramter to make sure the input is in a right manner. It is the sense of defensive programing. Be sure, don’t grant the input parameter. But actually it is quite boilet code for input parameter validation. For example, if we define a Report Interface: 123public interface Report &#123; void export(File file);&#125; And we have several different Reports to implement this interface, do we need to do the validate in every implementation? The answer is it depends, we can implement a DefaultReport, to decorate different report as example. 1234567891011121314151617public class DefaultReport implements Report &#123; @Override public void export(File file) &#123; if (file == null) &#123; throw new IllegalArgumentException( \"File is NULL; can't export.\" ); &#125; if (file.exists()) &#123; throw new IllegalArgumentException( \"File already exists.\" ); &#125; // Export the report to the file &#125;&#125; 1234567891011121314151617181920212223242526public class NoWriteOverReport implements Report &#123; private final Report origin; NoWriteOverReport(Report rep) &#123; this.origin = rep; &#125; @Override public void export(File file) &#123; if (file.exists()) &#123; throw new IllegalArgumentException( \"File already exists.\" ); &#125; this.origin.export(file); &#125; public static void main(String[] args) &#123; Report report = new NoWriteOverReport( new DefaultReport() ); File file = new File(\".\"); report.export(file); &#125;&#125; So we can reuse the default report valitor now.","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http:/tags/java/"},{"name":"patterns","slug":"patterns","permalink":"http:/tags/patterns/"}]},{"title":"Algorithm Big-O notion","slug":"real/ALGO-0-bigo","date":"2019-02-20T15:58:45.000Z","updated":"2019-07-29T04:15:36.756Z","comments":true,"path":"2019/02/20/real/ALGO-0-bigo/","link":"","permalink":"http:/2019/02/20/real/ALGO-0-bigo/","excerpt":"","text":"Algorithm Big-O notionreference","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http:/tags/java/"},{"name":"patterns","slug":"patterns","permalink":"http:/tags/patterns/"}]},{"title":"YUML Basic Usage","slug":"yuml-usage","date":"2018-12-23T16:00:36.000Z","updated":"2019-07-11T01:45:11.994Z","comments":true,"path":"2018/12/24/yuml-usage/","link":"","permalink":"http:/2018/12/24/yuml-usage/","excerpt":"","text":"YUML Syntax comments and directives class diagram Comments and Directives type: //{type:class} direction: // {direction:leftToRight} generate: // {generate:true} Class diagramcheetsheet for class diagram 123456789101112Class [Customer]Directional [Customer]-&gt;[Order]Bidirectional [Customer]&lt;-&gt;[Order]Aggregation [Customer]+-[Order] or [Customer]&lt;&gt;-[Order]Composition [Customer]++-[Order]Inheritance [Customer]^[Cool Customer], [Customer]^[Uncool Customer]Dependencies [Customer]uses-.-&gt;[PaymentStrategy]Cardinality [Customer]&lt;1-1..2&gt;[Address]Labels [Person]customer-billingAddress[Address]Notes [Address]-[note: Value Object]Full Class [Customer|Forename;Surname;Email|Save()]Color splash [Customer&#123;bg:orange&#125;]&lt;&gt;1-&gt;*[Order&#123;bg:green&#125;] Association classes1[Invoice]&lt;*-*&gt;[Products][Invoice Item] Use-cases diagram123456Use Case (Login)Actor [Customer]&lt;&lt;Extend&gt;&gt; (Login)&lt;(Forgot Password)&lt;&lt;Include&gt;&gt; (Register)&gt;(Confirm Email)Actor Inheritance [Admin]^[User]Note [Admin]-(note: Most privilidged user) Activity diagram12345678Start (start)End (end)Activity (Find Products)Flow (start)-&gt;(Find Products)Multiple Assoc. (start)-&gt;(Find Products)-&gt;(end)Decisions (start)-&gt;&lt;d1&gt;Decisions w/Label (start)-&gt;&lt;d1&gt;logged in-&gt;(Show Dashboard) and &lt;d1&gt;not logged in-&gt;(Show Login Page)Parallel (Action 1)-&gt;|a| and (Action 2)-&gt;|a| State diagram1234567Start (start)End (end)Activity (Find Products)Flow (start)-&gt;(Find Products)Multiple Assoc. (start)-&gt;(Find Products)-&gt;(end)Complex case (Simulator running)[Pause]-&gt;(Simulator paused|do/wait)[Unpause]-&gt;(Simulator running)Note (state)-(note: a note here) Deployment diagram1234Node [node1]Association [node1]-[node2]Labeled Assoc. [node1]label-[node2]Note [node1]-[note: a note here] Sequence diagram12345Object [Patron]Message [Patron]order food&gt;[Waiter]Response [Waiter]serve wine.&gt;[Patron]Note [Actor]-[note: a note message]Asynchronous [Patron]order food&gt;&gt;[Waiter] Package diagram123456Package [package1]Association [package1]-&gt;[package2]Labeled assoc [package1]label-&gt;[package2]Note [package1]-[note: a note here]` Others Color codes: form #RRGGBB, X11 color coding checkout yuml.me Toolsyuml-diagram 1npm install yuml-diagram","categories":[],"tags":[{"name":"tips","slug":"tips","permalink":"http:/tags/tips/"}]},{"title":"内网穿透方案 - frp","slug":"frp-usage","date":"2018-11-21T15:11:47.000Z","updated":"2019-07-11T01:45:11.874Z","comments":true,"path":"2018/11/21/frp-usage/","link":"","permalink":"http:/2018/11/21/frp-usage/","excerpt":"","text":"frp 使用golang编写的，下面几个例子来说明一下如何使用frp. todo reference","categories":[],"tags":[{"name":"tips","slug":"tips","permalink":"http:/tags/tips/"},{"name":"ops","slug":"ops","permalink":"http:/tags/ops/"}]},{"title":"似是而非","slug":"think-twice","date":"2018-11-20T01:25:03.000Z","updated":"2019-07-11T01:44:59.659Z","comments":true,"path":"2018/11/20/think-twice/","link":"","permalink":"http:/2018/11/20/think-twice/","excerpt":"","text":"很很多似是而非的问题，信息现在是爆炸，而不是太少。所以多思考，而不是不停的道听途说对自身更有意义。有些听上去很多的东西可能也是需要自己多想，多想其实简单来说就是要多方面考虑，要站在其他的角度考虑问题。 比如我们常说我们要问为什么，但是为什么不个人的答案可能都是不一样呀，为什么可能是为什么这么做，为什么要做，但是最基本最基本的问题应该是目的是什么，很多为什么马上牵扯到很多很专业的事前，但是目的应该是所有人都懂得，而专业内容实际上不是每个人都能懂得，如果你想知道目的是什么，但是别人告诉了你很多你听不懂的东西，那么这里面一定有GAP，一定哪里有问题没有被解决。同样如果已经进入到专业领域你听不懂，那么自己就需要补课了。 另外一点问为什么的时候，也要对自己进行反思，自己真的有能力去问这个为什么吗？有能力理解这里面的目的吗，如果不能，那么回去看书或者请教其他人了。 很多很丰富的鸡汤鸡汤为什么好听，因为能给你共鸣，同时比较能调动你的情绪，很容易有代入感，但是需要警惕的事，鸡汤不能帮你完成任何一件事情，它只是更容易让你上瘾，让你觉得在讨论宏大的问题，然而其实没几个人有能力讨论宏大问题。 鸡汤本身没有问题，但是如果觉得多喝了一点就有自己进步了，那么这个就是犯的大错；真正有价值的东西大体可以通过钱或者其他东西来衡量的，也就是交换价值；鸡汤有吗？鸡汤帮不了你.如果鸡汤是道，把事情做出来可以是术，但是大部分人应该是通过术来理解，推导出道来；如果只是被动接受那些道，那么你接受的本省就不是道，","categories":[],"tags":[{"name":"thoughts","slug":"thoughts","permalink":"http:/tags/thoughts/"}]},{"title":"学习ansible module-1","slug":"ansible-module-1","date":"2018-09-13T15:31:21.000Z","updated":"2019-07-29T04:08:35.586Z","comments":true,"path":"2018/09/13/ansible-module-1/","link":"","permalink":"http:/2018/09/13/ansible-module-1/","excerpt":"","text":"写一个Ansbile Module实际上非常容易，我从看 这个源码的方式大概可以了解Ansible的一个简单的123456789101112131415161718插件.下面分几个内容来看：- 插件运行代码- 插件的meta的数据## Ansible 插件代码- 首先Ansible 插件的入口函数为main函数所以先定义一个main函数，以及main函数的运行```pythondef main(): passmain() 实现main函数 主要步骤是： module定义，Ansible的module，定义这个AnsibleModule的argument_spec,这个里面用来声明这个插件使用的参数 module.params，ansible的输入为task的yml文件，这里面定义的内容都会传递到这个params中 然后根据不同的state的值去调用不同的任务，所有不同的任务的参数都是module，module用来传递了运行时的上下文 实现不同state对应的任务 基本上就结束了一个Ansible插件了 123456789101112131415161718192021222324252627282930module = AnsibleModule( argument_spec=dict( role=dict(choices=['standalone', 'hub', 'node'], default='standalone'), state=dict(choices=['running', 'stopped', 'restarted'], default='running'), version=dict(default='2.53.0'), path=dict(default='.'), force=dict(default=False, type='bool'), args=dict(required=False, default=''), java=dict(required=False, default='/usr/bin/java'), logfile=dict(required=False, default='./selenium.log'), javaargs=dict(required=False, default=[], type='list'), ), supports_check_mode=False, mutually_exclusive=[])state = module.params['state']role = module.params['role']if state == 'running': (changed, pid) = start(module) finish(module, msg='%s is running' % role, changed=changed, pid=pid)elif state == 'stopped': changed = stop(module) finish(module, msg='%s is stopped' % role, changed=changed)elif state == 'restarted': (changed, pid) = restart(module) finish(module, msg='%s has restarted' % role, changed=changed, pid=pid) start 任务的一个例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051def start(module): \"\"\" Start the Selenium standalone :param module: :return: \"\"\" _, jar_file = download(module) changed = False role = module.params['role'] if role != 'standalone': role = \"-role %s\" % role else: role = '' if not is_running(module): # in another implementation changed = True args = '' java_args = '' if module.params['args']: for (k, v) in module.params['args'].iteritems(): args += '-%s=%s ' % (k, v) if module.params['javaargs']: for arg in module.params['javaargs']: java_args += '-%s ' % arg java_executable = os.path.abspath(os.path.expandvars(module.params['java'])) log_file = os.path.abspath(os.path.expandvars(module.params['logfile'])) cmd = \"%s %s -jar %s %s %s &gt;&gt; %s 2&gt;&amp;1 &amp;\" % (java_executable, java_args, jar_file, role, args, log_file) os.setsid() #print cmd rc = os.system(cmd) if rc != 0: abort(module, 'Running the %s role returned code %s !' % (role, rc)) pid = get_pid(module) if pid: return changed, pid else: abort(module, 'Couldnt fetch the pid of the running %s ! It may have ended abruptly.' % module.params['role']) Meta 插件的meta的数据meta信息一般存放在meta目录中，具体写的方式参考源码:https://github.com/SeleniumHQ/ansible-selenium.git Ansible MindMap","categories":[],"tags":[{"name":"ansible","slug":"ansible","permalink":"http:/tags/ansible/"},{"name":"CICD","slug":"CICD","permalink":"http:/tags/CICD/"}]},{"title":"conda-cheatsheet","slug":"conda-cheetsheet","date":"2018-09-12T05:49:17.000Z","updated":"2019-07-11T01:44:23.310Z","comments":true,"path":"2018/09/12/conda-cheetsheet/","link":"","permalink":"http:/2018/09/12/conda-cheetsheet/","excerpt":"","text":"CONDA Cheat Sheet Conda Basics Command Usage conda info version conda update conda update conda conda install install package spyder run a package after installed conda update update package Using Environment Command Usage conda create –name py36 python=3.6 create a new python3.6 environment source activate py36 activate env conda env list list all environment conda create –clone –name clone project conda list –explicit &gt; py36.txt save environment to a text file conda env create –file py36.txt creat environment from a text file pip install boltons pip install to the activate environment conda search PACKAGENAME search packages conda env remove –name env_name remove environment","categories":[],"tags":[{"name":"cheatsheet","slug":"cheatsheet","permalink":"http:/tags/cheatsheet/"}]},{"title":"jmespath 使用，jsonpath外的另外一种选择","slug":"jmespath","date":"2018-08-13T14:35:32.000Z","updated":"2019-07-29T04:05:38.300Z","comments":true,"path":"2018/08/13/jmespath/","link":"","permalink":"http:/2018/08/13/jmespath/","excerpt":"","text":"在测试过程中，经常会去JSON中的某个值，jmespath可以是除了jsonpath的另外一种选择.下面通过几个例子来说明jmespath在python的使用 jmespath python安装非常简单直接pip, 1pip install jmespth 查询一个key值123source=&#123;\"a\": \"foo\", \"b\": \"bar\", \"c\": \"baz\"&#125;result = jmespath.search(\"a\",source)print(result) subexpression类似于jsonpath，通过.来表示路径的层级 123source_1=&#123;\"a\": &#123;\"b\": &#123;\"c\": &#123;\"d\": \"value\"&#125;&#125;&#125;&#125;sub_result = jmespath.search(\"a.b.c\",source_1)print(sub_result) 这个例子的结果为：{‘d’: ‘value’} index expressionsindex expression主要使用在数组上 123source_2 = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"]index_result = jmespath.search(\"[1]\",source_2)print(index_result) 这个例子的结果为:b 多个表达式综合使用以上几种表达式可以合起来一期使用： 123456789101112composite_exp = \"a.b.c[0].d[1][0]\"source_3= &#123;\"a\": &#123; \"b\": &#123; \"c\": [ &#123;\"d\": [0, [1, 2]]&#125;, &#123;\"d\": [3, 4]&#125; ] &#125;&#125;&#125;composite_result = jmespath.search(composite_exp,source_3)print(composite_result) 这个例子的结果为1 Slicing 切片slicing 和python本身的slicing比较像， 1234source_4=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]slicing_exp = \"[0:5]\"slicing_result = jmespath.search(slicing_exp,source_4)print(slicing_result) 这个例子的结果为： [0, 1, 2, 3, 4] slicing实际上和python自己的机制基本一样，同样这个也是主要给数组使用.有一点需要记住，基本的slicing的格式其实是： [start:stop:step] Projectionsprojection不知道怎么翻译，就先叫做投影吧，具体通过例子来说比较好理解.projections主要包含一下几种情况: List Projections Slice Projections Object Projections Flatten Projections Filter Projections Projections- 例子12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182list_exp=\"people[*].first\"source_5 = &#123; \"people\": [ &#123;\"first\": \"James\", \"last\": \"d\"&#125;, &#123;\"first\": \"Jacob\", \"last\": \"e\"&#125;, &#123;\"first\": \"Jayden\", \"last\": \"f\"&#125;, &#123;\"missing\": \"different\"&#125; ], \"foo\": &#123;\"bar\": \"baz\"&#125;&#125;proj_result1= jmespath.search(list_exp,source_5)print(proj_result1) # ['James', 'Jacob', 'Jayden']obj_exp =\"reservations[*].instances[*].state\"source_6= &#123; \"reservations\": [ &#123; \"instances\": [ &#123;\"state\": \"running\"&#125;, &#123;\"state\": \"stopped\"&#125; ] &#125;, &#123; \"instances\": [ &#123;\"state\": \"terminated\"&#125;, &#123;\"state\": \"runnning\"&#125; ] &#125; ]&#125;proj_result2=jmespath.search(obj_exp,source_6)print(proj_result2) #[['running', 'stopped'], ['terminated', 'runnning']]# Flatten projectionssource_7=[ [0, 1], 2, [3], 4, [5, [6, 7]]]flat_exp =\"[]\"flat_result = jmespath.search(flat_exp,source_7)print(flat_result) # [0, 1, 2, 3, 4, 5, [6, 7]]# filterfilter_exp=\"machines[?state=='running'].name\"filter_source =&#123; \"machines\": [ &#123;\"name\": \"a\", \"state\": \"running\"&#125;, &#123;\"name\": \"b\", \"state\": \"stopped\"&#125;, &#123;\"name\": \"b\", \"state\": \"running\"&#125; ]&#125;filter_result = jmespath.search(filter_exp,filter_source)print(filter_result)# pipe expressionpipe_exp= \"people[*].first | [0]\"pipe_source= &#123; \"people\": [ &#123;\"first\": \"James\", \"last\": \"d\"&#125;, &#123;\"first\": \"Jacob\", \"last\": \"e\"&#125;, &#123;\"first\": \"Jayden\", \"last\": \"f\"&#125;, &#123;\"missing\": \"different\"&#125; ], \"foo\": &#123;\"bar\": \"baz\"&#125;&#125;pipe_result = jmespath.search(pipe_exp,pipe_source)print(pipe_result) # James# multiselectmulti_exp=\"people[].[first,last]\"multiselect_result = jmespath.search(multi_exp,pipe_source)print(multiselect_result) # [['James', 'd'], ['Jacob', 'e'], ['Jayden', 'f'], [None, None]] 基本上把网站上例子试了一下，总体感觉功能是相当强大(怀疑比jsonpath还要厉害一点).从简单到复杂，都还是比较好用.","categories":[],"tags":[{"name":"python","slug":"python","permalink":"http:/tags/python/"},{"name":"tips","slug":"tips","permalink":"http:/tags/tips/"}]},{"title":"Agile Metrics： 敏捷指标","slug":"3-Agile-Metrics","date":"2018-08-10T13:29:37.000Z","updated":"2019-07-11T01:45:30.828Z","comments":true,"path":"2018/08/10/3-Agile-Metrics/","link":"","permalink":"http:/2018/08/10/3-Agile-Metrics/","excerpt":"","text":"有句话说的好，不能衡量就不能说明任何问题，那么一个敏捷项目，需要用什么样的指标来衡量呢？ 不管怎么样有些规则对于指标来说是必须的: 必须追踪有用的信息 指标的上下文也很重要 我能想到的指标包括: Story Point - Output Every Issue start-to-close time: Time Bug Ratio: Output/Debt Business Data for the new feature or fix bug: Output Techinical debt: own ? How Much? Story Point Figure out Spring Checklist What Value did the team deliver last sprint? How has the level of technical debt? Are you happy working with your teammate? Lead Time and Cycle Time","categories":[],"tags":[{"name":"agile metrics","slug":"agile-metrics","permalink":"http:/tags/agile-metrics/"}]},{"title":"junit-perf","slug":"1-junit-perf","date":"2018-07-24T14:11:05.000Z","updated":"2019-07-11T01:45:40.415Z","comments":true,"path":"2018/07/24/1-junit-perf/","link":"","permalink":"http:/2018/07/24/1-junit-perf/","excerpt":"","text":"使用JunitPerf进行性能测试以下简单介绍一下如何使用JunitPerf进行性能测试，JunitPerf是基于JUnit4的一个单元性能测试插件，对于会远程调用API测试比较合适，如果想要比较nanosecond 延迟的则需要使用JMH. JunitPerf 依赖声明此例子假设使用MAVEN管理项目，所以在POM文件中添加： 12345678910&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.noconnor&lt;/groupId&gt; &lt;artifactId&gt;junitperf&lt;/artifactId&gt; &lt;version&gt;1.9.1&lt;/version&gt;&lt;/dependency&gt; 构建压力测试类假设你想衡量DemoPerfService 类中的getServiceId方法： 1234567public class DemoPerfService &#123; public String getServiceId(String userId)&#123; return UUID.randomUUID().toString(); &#125;&#125; 那么你可以构建如下的测试类： 12345678910111213141516public class DemoServiceTest &#123; @Rule public JUnitPerfRule perfTestRule = new JUnitPerfRule(); DemoPerfService demoPerfService; @Before public void setupService()&#123; this.demoPerfService = new DemoPerfService(); &#125; @Test @JUnitPerfTest(threads = 50,durationMs = 1200,warmUpMs = 100,maxExecutionsPerSecond = 110) public void getServiceId_withoutTestRequirement() &#123; String result =demoPerfService.getServiceId(\"userid\"); System.out.println(result); Assert.assertNotNull(result); &#125; 直接运行就可以进行压力测试,默认的测试报告可以在build/reports 目录下获取： 以下是对于测试类的几点说明： Item 定义说明 Default值或说明 @Rule 申明为JUnit 的Rule类 JUnitPerfRule JUnitPerf 测试规则类 @JunitPerfTest 声明为性能测试方法 threads 测试使用的线程数 durationMs 测试持续时间 warmUpMs 测试热身时间 热身时间的测试数据不会计算进最后的测试结果 maxExecutionsPerSecond 方法执行的上限 RateLimiter，控制TPS上限 对自己的测试设置期望值使用@JUnitPerfTestRequirement 可以给性能测试设置期望值，这个annotation的属性有: 属性 定义 percentits 设置例如90%/95%/50% 响应时间的期望 executionsPerSec 期望每秒执行测试(TPS) allowedErrorPercentage 允许错误比例 minLatency 期望最小延时，如果实际最小延时超过这个数，则失败 maxLatency 期望最大延时，如果实际最大延时超过这个，则失败 meanLatency 期望中位数延时 下面是使用了JUnitPerfTestRequirement的一个测试方法,需要和@JUnitPerfTest一起使用： @JUnitPerfTest 定义了压测的运行参数 @JUnitPerfTestRequirement定义了压测的期望值 具体代码如下例: 123456789@Test @JUnitPerfTest(threads = 50,durationMs = 1200,warmUpMs = 100,maxExecutionsPerSecond = 110) @JUnitPerfTestRequirement(percentiles = \"90:7,95:7,98:7,99:8\", executionsPerSec = 10_000, allowedErrorPercentage = 0.10f) public void getServiceId() &#123; String result =demoPerfService.getServiceId(\"userid\"); System.out.println(result); Assert.assertNotNull(result); &#125; 运行之后，如果发现没有满足JUnitPerfTestRequirement定义，则报错: 1234java.lang.AssertionError: Test throughput threshold not achievedExpected: is &lt;true&gt; but: was &lt;false&gt;Expected :is &lt;true&gt; 是不是很简单！ 设置测试报告地址JUnitPerf 有不同的测试报告，个人觉得HTML的测试报告比较实用，具体只需要: 12@Rulepublic JUnitPerfRule perfTestRule = new JUnitPerfRule(new HtmlReportGenerator(\"perf/report.html\")); 完整的例子1234567891011121314151617181920212223242526272829public class DemoServiceTest &#123; @Rule// public JUnitPerfRule perfTestRule = new JUnitPerfRule(new HtmlReportGenerator(\"perf/report.html\")); public JUnitPerfRule perfTestRule = new JUnitPerfRule(); DemoPerfService demoPerfService; @Before public void setupService()&#123; this.demoPerfService = new DemoPerfService(); &#125; @Test @JUnitPerfTest(threads = 50,durationMs = 1200,warmUpMs = 100,maxExecutionsPerSecond = 110) @JUnitPerfTestRequirement(percentiles = \"90:7,95:7,98:7,99:8\", executionsPerSec = 10_000, allowedErrorPercentage = 0.10f) public void getServiceId() &#123; String result =demoPerfService.getServiceId(\"userid\"); System.out.println(result); Assert.assertNotNull(result); &#125; @Test @JUnitPerfTest(threads = 50,durationMs = 1200,warmUpMs = 100,maxExecutionsPerSecond = 110) public void getServiceId_withoutTestRequirement() &#123; String result =demoPerfService.getServiceId(\"userid\"); System.out.println(result); Assert.assertNotNull(result); &#125;&#125; 最后可以再设定的目录中查看测试报告，测试报告和默认的HTML 测试报告是一致的. 一点问题压力测试过程中，有时数据不能复用，举个例子来说，如果想测试完全没有访问redis缓存情况下，通过userid查询的user信息速度，那么压测的时候userid就不能复用，因为一旦访问了就会放入redis缓存而影响结果，这个可以通过使用其他的方法解决，比如曾今使用过BlockingQueue的方法进行过尝试，具体方法如下： 读取所有userid的文件 把userid放到一个BlockingQueue中 压测时获取userid通过BlockingQueue去获取 这样就解决了数据不能重复的方法，具体方法可以参考如下代码: 1234567891011121314151617181920212223242526272829303132333435 static BlockingQueue&lt;String&gt; distinctIdQueue ; @Rule public JUnitPerfRule perfTestRule = new JUnitPerfRule(new HtmlReportGenerator(\"data/report_test.html\")); @BeforeClass public static void setupQueue() throws IOException &#123; distinctIdQueue = new LinkedBlockingQueue&lt;&gt;(); Files.readAllLines( Paths.get(\"data/userid.txt\") ).parallelStream().forEach( item-&gt; &#123; try &#123; distinctIdQueue.put(item); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; ); &#125; @Test @JUnitPerfTest(threads = 50,durationMs = 1200,warmUpMs = 100,maxExecutionsPerSecond = 110) @JUnitPerfTestRequirement(percentiles = \"90:7,95:7,98:7,99:8\", executionsPerSec = 10_000, allowedErrorPercentage = 0.10f) public void getServiceId() &#123; String uesrId = distinctIdQueue.take(); String result =demoPerfService.getServiceId(userId); System.out.println(result); Assert.assertNotNull(result); &#125; &#125;","categories":[],"tags":[{"name":"junit","slug":"junit","permalink":"http:/tags/junit/"},{"name":"performance","slug":"performance","permalink":"http:/tags/performance/"}]},{"title":"Unit Testing Intro","slug":"0-ut-junit","date":"2018-07-18T14:35:49.000Z","updated":"2019-07-11T01:45:40.398Z","comments":true,"path":"2018/07/18/0-ut-junit/","link":"","permalink":"http:/2018/07/18/0-ut-junit/","excerpt":"","text":"Just DO It - Unit TestingThis is first blog for just do it series. The purpose for the just do it series is quit personal. As an aged tester, I have tried a bunch of different testing. And obviously,I am good at some types, and only have concepts in some other types.But There is no notes taken for these, sometimes it bothers me a lot when I need to explain or demo. Anthoer main reason is that I believe that when you want to test something, you need to understand what you test, it is not only the superficial workflow or business logic, but also some techincal inside. just do it is for all the testings or components I have experienced and learned. It is like footprints of my long enough tester jouney. And Just Do it is more than any words. ps: for learning English, I decided to write it in English at first. Unit Testing ParadoxThere are many blogs out there claiming Unit Testing is such a good thing for improve product quality,and it is quick and cheap. Some Evangelists even claimed unit testing plays very import role in agile,CI/CD process. But in reality, writing unit testing is very rare in a large amount of companies here China. Why? Why good thing doesn’t happen? It is quick,improving quality, more important is cheap? Why so many people/companies don’t buy in? I don’t know, but I want to dive it for seeking the reason. JUnit TryJUnit is a very popular unit testing framework, so Let me try from this. Build a Simple Demo ApplicationBut hold on,what application is for testing? OK, Let me build to simple ToDoApplication. What Features are included: Create ToDoItem : create a ToDoItem which status is TODO Update ToDoItme: update a ToDoItem Delete ToDoItem: set ToDoItem status to deleted Complete ToDoItem: set ToDoItem status to completed I try to make it as simple as possible, so the demonstrate these futures, I create three classes: ToDOItem: it is an entity, which is used to save to database. Just treat it as a database table ToDoItemDTO: it is a DTO entity, treat is as input ToDoItemService: do the transformation, transfer ToDoItemDTO to ToDoItem Here is very simple codes: 1234567public class ToDoItem &#123; private String id; private String desc; private String details; private int status; private Long userId;&#125; 1234567public class ToDoItemDTO &#123; private String id; private String desc; private String details; private int status=ToDoStatusEnum.TODO.getStatusId(); private Long userId;&#125; 12345678910111213141516171819202122232425public class ToDoService &#123; public ToDoItem createToDoItem(ToDoItemDTO dto)&#123; ToDoItem toDoItem = new ToDoItem(); toDoItem.setId(UUIDGenerator.generateToDoId()); toDoItem.setStatus(dto.getStatus()); toDoItem.setDesc(dto.getDesc()); toDoItem.setDetails(dto.getDetails()); toDoItem.setUserId(dto.getUserId()); return toDoItem; &#125; public ToDoItem updateToDoItem(ToDoItemDTO dto)&#123; return createToDoItem(dto); &#125; //todo: should make todo item statue to DELETED public ToDoItem deleteToDoItem(ToDoItemDTO dto)&#123; return createToDoItem(dto); &#125; //todo: should make todo item statue to Completed public ToDoItem completeToDoItem(ToDoItemDTO dto)&#123; return createToDoItem(dto); &#125;&#125; 12345678910111213public enum ToDoStatusEnum &#123; TODO(0),WIP(1),DONE(2),PENDING(3),DELETED(4); public int getStatusId() &#123; return statusId; &#125; private final int statusId; ToDoStatusEnum(int statusId) &#123; this.statusId= statusId; &#125;&#125; Let’s create first JUNIT Test casesIt is obviously the input is an instance of ToDoDTO, and the output is ToDoItem and the most important part to test is ToDoService. So first thing first, here is the first one test case for ToDoServicce, to test create todoitem successfully, and the content in DTO should be same as the new created ToDoItem. 12345678910111213141516171819import org.junit.Assert;import org.junit.BeforeClass;import org.junit.Test;public class ToDoServiceTest &#123; @Test public void testCreateToDoItem_successful() &#123; ToDoService toDoService; = new ToDoService(); ToDoItemDTO dto = new ToDoItemDTO(); dto.setDesc(\"test todo\"); dto.setDetails(\"test todo details\"); ToDoItem toDoItem =toDoService.createToDoItem(dto); Assert.assertEquals(toDoItem.getDesc(),\"test todo\"); Assert.assertEquals(toDoItem.getDetails(),\"test todo details\"); Assert.assertEquals(toDoItem.getStatus(),ToDoStatusEnum.TODO.getStatusId()); &#125;&#125; Here I only use two JUNIT elements, these two elements will be used many many times, if you are writing test codes. @Test: annotation test mark the method as test method Assert.assertEquals: compare the expected value and actual value It is quit straightforward, when you test something, give the input, process it, and compare the output to the expected value, if meet, pass, otherwise failed. More casesAfter Complete the first case, let’s do more. We want to test more functionalities, like update,delete, complete todoitem. Here you go: 123456789101112131415161718192021222324252627282930313233343536373839404142public class ToDoServiceTest &#123; public static ToDoService toDoService; public static ToDoItemDTO dto ; @BeforeClass public static void setupToDoService()&#123; toDoService = new ToDoService(); dto = new ToDoItemDTO(); &#125; @Test public void testCreateToDoItem_successful() &#123; dto.setDesc(\"test todo\"); dto.setDetails(\"test todo details\"); ToDoItem toDoItem =toDoService.createToDoItem(dto); Assert.assertEquals(toDoItem.getDesc(),\"test todo\"); Assert.assertEquals(toDoItem.getDetails(),\"test todo details\"); Assert.assertEquals(toDoItem.getStatus(),ToDoStatusEnum.TODO.getStatusId()); &#125; @Test public void updateToDoItem_successful() &#123; dto.setDesc(\"update\"); dto.setDetails(\"update\"); ToDoItem toDoItem =toDoService.createToDoItem(dto); Assert.assertEquals(toDoItem.getDesc(),\"update\"); Assert.assertEquals(toDoItem.getDetails(),\"update\"); &#125; @Test public void deleteToDoItem() &#123; ToDoItem toDoItem =toDoService.deleteToDoItem(dto); Assert.assertEquals(toDoItem.getStatus(),ToDoStatusEnum.DELETED.getStatusId()); &#125; @Test public void completeToDoItem() &#123; ToDoItem toDoItem =toDoService.deleteToDoItem(dto); Assert.assertEquals(toDoItem.getStatus(),ToDoStatusEnum.DELETED.getStatusId()); &#125;&#125; In above codes, I use a new junit annonations: @BeforeClass @BeforeClass is invoked before the test class initialized. So the method and should be static. Here why I used @BeforeClass is because I want to resue the toDoService accross all the test methods. So it should be a static. And another Junit annotation @Before is simmilar with @BeforeClass.It is invoked before every test method. Here is a sample codes to show it: 1234567891011121314151617181920public class JunitAnnotationDemo &#123; String testString=\"First\"; @Before public void setUp()&#123; testString = this.testString + \",setup\"; System.out.println(this); &#125; @Test public void testTestString_First()&#123; System.out.println(testString); &#125; @Test public void testTestString_Second()&#123; System.out.println(testString); &#125;&#125; From the result of System.out.println(this), actually JUNIT use different instance to run the test methods 1234io.hedwig.justdoit.demo.JunitAnnotationDemo@17d10166First,setupio.hedwig.justdoit.demo.JunitAnnotationDemo@4f8e5cdeFirst,setup Run the testsBack to the ToDoItem unit tests. Run the ToDoServiceTest, there are several errors, here is an example for deleteToDoItem: 1234java.lang.AssertionError: Expected :0Actual :4 &lt;Click to see difference&gt; The target to unit test is to make sure you codes pass the tests quickly. Look back to ToDoService, it is obviously, deleteToDoItem should set the ToDoItem status to DELETE, but the function is omitted. So add the codes to fix it, and re-run the tests to make it all passed. Unit Test ThinkingActully this process is as known as TDD (Test Driven Development). Before actually complete the real working codes, write test codes first. The purpose of these test codes, I think they could be : Features Definition Task Tracking Tool Boundary Checking Tool Why? I think in reality, there are many undocumented features in PRD, no one actually mantained it. Unit Test documents these features. Also if writes test codes before complete the real codes, then you pass test methods one by one, that means developer complete the sub-tasks one by one, so It is Task Tracking tool. Imaging that, if you want to complete 10 sub-tasks, but you are interruptted every hour by meetings or chattings. Every time develop want to find where to start, just run the unit tests, then start from the failed tests. There are always boundary cases, write into codes to check, it helps develop to find bugs, and also it could be checked if develop have some new changes. What should be paid for Unit TestsAbove cases looks so fascination, Unit Tests could tracking features,tasks, and check the codes when changes happened to ensure your changes are correct. But Why developers still don’t want to write the Unit tests? Let’s just counting the lines of code in above examples, the truth is that the test codes are more lines than real codes. It is not joke, it happened. So I can understand why developer don’t want to write unit tests, maybe the workload!! Understand what the develop thoughts are, it is also one of targets in just do it series, try it and then find where the issues are. Because write testing codes need to take more times, pick what to test and use less test codes to achieve coverages is more critical and practical. code repo","categories":[],"tags":[{"name":"ut","slug":"ut","permalink":"http:/tags/ut/"},{"name":"justdoit","slug":"justdoit","permalink":"http:/tags/justdoit/"}]},{"title":"ansible In 30 Minutes","slug":"1-ansible-in-10-minutes","date":"2018-07-01T13:34:04.000Z","updated":"2019-07-11T01:45:21.655Z","comments":true,"path":"2018/07/01/1-ansible-in-10-minutes/","link":"","permalink":"http:/2018/07/01/1-ansible-in-10-minutes/","excerpt":"","text":"Ansible Basic Conceptansible 是一个操作机器的工具,可以通过编排不同的inventory,组合不同的命令来将日常运维的操作变成可运行的脚本资产,同时也可以积累常用的脚本以便复用. 下面是关于ansible的一些基础概念的脑图,总体而言ansible包括了以下几个概念： inventory: 定义主机,定义操作对象 Host:主机 Group：不同的主机组合成一个组，一个组下面可以有子组，于是就构成了一个树形结构 variable： 变量，主要用来定义对于操作机器时使用的可变参数 Ansible Installation install in MAC 12brew unisntall ansiblebrew install ansible install in centos 12sudo yum install epel-releasesudo yum install ansible -y Configure hosts for ansible ssh connector copy ssh key to different hosts 1234ssh-keygenssh-copy-id remoteuser@remote.serverssh-keyscan remote.server &gt;&gt; ~/.ssh/known_hosts check ssh connection 1ssh remoteuser@remote.server it is done. Ansible Ad-hoc Commandsansible 命令的pattern 如下： 1ansible &lt;host-pattern&gt; [options] 具体查看ansible 的使用帮助是： 1ansible --help ansible ad-hoc command - 检查安装环境1ansible all -m ping -u root ansible ad-hoc command - 执行命令1ansible all -a \"/bin/sh echo hello world\" ansible ad-hoc command - copy files1ansible web -m copy -a \"src=/etc/hosts dest=/tmp/hosts\" ansible ad-hoc command - yum install1ansible web -m yum -a \"name=acme state=present\" ansible ad-hoc command - add user1ansible all -m user -a \"name=foo passsword=&lt;crypted password here&gt;\" ansible ad-hoc command - download git 包1ansible web -m git -a \"repo=git://foo.example.io/repo.git dest=/src/myapp\" ansible ad-hoc command - start service1ansible web -m service -a \"name=httpd state=started\" ansible ad-hoc command - 并行运行1ansible web -a \"/sbin/reboot\" -f 10 ansible ad-hoc command - 查看全部系统信息1ansible all -m setup ansible ad-hoc command 小结从以上的例子中我们可以看到ansible的命令一般都会使用如下几点： module: -m module_args: -a hosts: all/web/…… 以上三个组合成为了下面的一个命令： 1ansible all -m service -a \"name=httpd state=started\" 从python的角度看,可以用伪代码的方式: 1234567891011121314151617181920212223242526272829def copy(args=&#123;&#125;): for kwarg, v in args.items(): print(\"&#123;key&#125;=&#123;value&#125;\".format(key=kwarg, value=v))def test(args=&#123;&#125;): for kwarg, v in args.items(): print(\"&#123;key&#125;=&#123;value&#125;\".format(key=kwarg, value=v))module_mapping = &#123; \"copy\": copy, \"test\": test&#125;def ansible(module, module_args): func = module_mapping.get(module) parsed = module_args.split(\" \") args = &#123;&#125; for module_arg in parsed: kv = module_arg.split(\"=\") args[kv[0]] = kv[1] func(args)if __name__ == '__main__': ansible(module='copy', module_args=\"name=name test=test\")","categories":[],"tags":[{"name":"CI/CD","slug":"CI-CD","permalink":"http:/tags/CI-CD/"},{"name":"ansible","slug":"ansible","permalink":"http:/tags/ansible/"}]},{"title":"Travis - GithubToolChain-1","slug":"2-Github-Travis","date":"2018-07-01T13:34:04.000Z","updated":"2019-07-11T01:45:21.799Z","comments":true,"path":"2018/07/01/2-Github-Travis/","link":"","permalink":"http:/2018/07/01/2-Github-Travis/","excerpt":"","text":"Github工具系列-TravisTravis 是一个持续集成工具，github上的每一次提交都可以触发一次build. 在说Travis之前，先说说持续集成，Continuous Integration(CI)的概念。 CI 这是martin flow关于持续集成的一片文章。CI简而言之就是一个开发的方式，这个方式有别于瀑布式开发中在所有功能(大量代码)完成之后才进行验证，他提倡通过不停的提交一个个小功能(代码2量不那么大)进行验证。很显然采用这种开发方式，会带来频繁的build和test，因此也催生了Jenkins等持续集成的工具。Travis也是这种工具，和Jenkins不同的是，Travis更像一种云服务，不需要你在本地部署。 回到CI这个话题，为什么要采用CI这个方式呢？他有什么好处呢？CI的好处是： ···通过不停的build,test可以对功能，代码获取快速的反馈，进行快速的修复，因此项目的进度实际上是非常稳定的，出现在产品开发完之后，产品，需求方向出现错误会尽可能的避免··· 从目前来看，国内很多公司大都采用了CI的方式，大型一些的公司每天都有成千上万的build，test在自动化的进行，没有一个工具来做这些的话，可以想象成本会有多高，也就无从谈起或者实施CI了。有一点比较佩服老外，他们如果觉得方向是正确的，就会想办法通过工具或者其他手段来实现，软件行业的各种思想，大部分都是老外提出的。(critical thinking这个方面也是我自己要好好提高的） Run Travis.travis.yml file for JAVA .travis,yml detailreference Building,testing,deployment Builds,Jobs,Stages and Phases phases, sequential steps of a jab build, a group of jobs job, serveral phases stage travis phases: before_install install before_script script","categories":[],"tags":[{"name":"CI/CD","slug":"CI-CD","permalink":"http:/tags/CI-CD/"}]},{"title":"马桶测试-1： 创建干净的测试数据","slug":"1-CleanlyTestData","date":"2018-07-01T13:29:37.000Z","updated":"2019-07-11T01:45:30.679Z","comments":true,"path":"2018/07/01/1-CleanlyTestData/","link":"","permalink":"http:/2018/07/01/1-CleanlyTestData/","excerpt":"","text":"马桶测试-1： 创建干净的测试数据Google Testing on the Toilet Series 翻译第一篇,创建干净的测试数据 原文 Origin Testing on the Toilet: Cleanly Create Test Data Helper方法让创建数据非常方便，但是随着时间的推移，不同的变量数据创建方法加入之后，代码可读性变得不那么好了. 1234567891011121314// This helper method starts with just a single parameter:Company company = newCompany(PUBLIC);// But soon it acquires more and more parameters.// Conditionals creep into the newCompany() method body to handle the nulls,// and the method calls become hard to read due to the long parameter lists:Company small = newCompany(2, 2, null, PUBLIC);Company privatelyOwned = newCompany(null, null, null, PRIVATE);Company bankrupt = newCompany(null, null, PAST_DATE, PUBLIC);// Or a new method is added each time a test needs a different combination of fields:Company small = newCompanyWithEmployeesAndBoardMembers(2, 2, PUBLIC);Company privatelyOwned = newCompanyWithType(PRIVATE);Company bankrupt = newCompanyWithBankruptcyDate(PAST_DATE, PUBLIC); 为了让测试数据代码更据可读性，使用builder pattern，通过返回部分数据的builder类来创建数据，修改不同的状态是一个不错的方法。 创建数据的方法可以生成部分的默认数据，之后再修改需要修改的数据，可以让测试代码方便而且容易阅读，如下例： 1234567891011Company small = newCompany().setEmployees(2).setBoardMembers(2).build();Company privatelyOwned = newCompany().setType(PRIVATE).build();Company bankrupt = newCompany().setBankruptcyDate(PAST_DATE).build();Company arbitraryCompany = newCompany().build();// Zero parameters makes this method reusable for different variations of Company.// It also doesn’t need conditionals to ignore parameters that aren’t set (e.g. null// values) since a test can simply not set a field if it doesn’t care about it.private static Company.Builder newCompany() &#123; return Company.newBuilder().setType(PUBLIC).setEmployees(100); // Set required fields&#125; 同时测试不应该以来任何的默认值，如果有依赖就让使用者必须去了解具体的创建数据方法的实现了。 123// This test needs a public company, so explicitly set it.// It also needs a company with no board members, so explicitly clear it.Company publicNoBoardMembers = newCompany().setType(PUBLIC).clearBoardMembers().build(); 更多详细信息可以参考：http://www.natpryce.com/articles/000714.html 附上原文：This article was adapted from a Google Testing on the Toilet (TotT) episode. You can download a printer-friendly version of this TotT episode and post it in your office.By Ben YuHelper methods make it easier to create test data. But they can become difficult to read over time as you need more variations of the test data to satisfy constantly evolving requirements from new tests: 1234567891011121314// This helper method starts with just a single parameter:Company company = newCompany(PUBLIC);// But soon it acquires more and more parameters.// Conditionals creep into the newCompany() method body to handle the nulls,// and the method calls become hard to read due to the long parameter lists:Company small = newCompany(2, 2, null, PUBLIC);Company privatelyOwned = newCompany(null, null, null, PRIVATE);Company bankrupt = newCompany(null, null, PAST_DATE, PUBLIC);// Or a new method is added each time a test needs a different combination of fields:Company small = newCompanyWithEmployeesAndBoardMembers(2, 2, PUBLIC);Company privatelyOwned = newCompanyWithType(PRIVATE);Company bankrupt = newCompanyWithBankruptcyDate(PAST_DATE, PUBLIC); Instead, use the test data builder pattern: create a helper method that returns a partially-built object (e.g., a Builder in languages such as Java, or a mutable object) whose state can be overridden in tests. The helper method initializes logically-required fields to reasonable defaults, so each test can specify only fields relevant to the case being tested: 1234567891011Company small = newCompany().setEmployees(2).setBoardMembers(2).build();Company privatelyOwned = newCompany().setType(PRIVATE).build();Company bankrupt = newCompany().setBankruptcyDate(PAST_DATE).build();Company arbitraryCompany = newCompany().build();// Zero parameters makes this method reusable for different variations of Company.// It also doesn’t need conditionals to ignore parameters that aren’t set (e.g. null// values) since a test can simply not set a field if it doesn’t care about it.private static Company.Builder newCompany() &#123; return Company.newBuilder().setType(PUBLIC).setEmployees(100); // Set required fields&#125; Also note that tests should never rely on default values that are specified by a helper method since that forces readers to read the helper method’s implementation details in order to understand the test.// This test needs a public company, so explicitly set it.// It also needs a company with no board members, so explicitly clear it.Company publicNoBoardMembers = newCompany().setType(PUBLIC).clearBoardMembers().build();You can learn more about this topic at http://www.natpryce.com/articles/000714.html","categories":[],"tags":[{"name":"google_test_blog_translation","slug":"google-test-blog-translation","permalink":"http:/tags/google-test-blog-translation/"}]},{"title":"Clean Code Reading Note","slug":"2-CleanCode","date":"2018-07-01T13:29:37.000Z","updated":"2019-07-11T01:45:30.765Z","comments":true,"path":"2018/07/01/2-CleanCode/","link":"","permalink":"http:/2018/07/01/2-CleanCode/","excerpt":"","text":"Clean Code/The Art of Readable Code Reading Notes12知易行难理念可能都有，那么怎么做呢？ 匆匆看过两本书，两本书提供了一些如何写好代码的纲领，当时很明显真要写好不是读完两本书就可以的。多练，多思考才可以。两本书有不少比较相似的内容，所以很明显这些相似的内容就是日常需要关注的地方，不管是注释，方法命名，变量命名，重构这些都是日常工作中时刻注意的。 Clean Code和The Art of Readable Code看完对于我来说，更多的是对于作者面面俱到细节的描述惊讶，居然有人能把这些琐碎的事情说的这么完整和逻辑感十足。可以说健壮的代码关于细节的处理是相当的繁琐，把繁琐的事情写成Clean Code不是一件容易事情，我们不缺理念，我们缺的是细节，谁都说我要写漂亮整齐的代码，然后怎么做到呢？我们抱怨别人的代码混乱，但是我们重写真的可以写的刚好吗？如果我们想写的好，那要如何去做呢？这本书给出了一些答案，而这些就是我学习的要点。 Clean Code-chapter 1介绍这个章节讲述了几个关于混乱代码的伤害(实际上是关于公司/产品的生存问题)，引用了不同技术大牛对于Clean Code的一些看法同时引出下面作者要写的关于Clean code的内容。大多数大牛们的说法都比价抽象，所以能记住的不多，下面是个印象比较的说法： Equals Never```123456789101112131415- 没有测试代码，就没有Clean Code(当然是TDD派)- 没有重复代码，可读性好，小块代码- 童子军军规：让营地比你来的时更干净，一点点清理，一点点消除，慢慢变成clean code- 读代码：写代码=10:1，读远远超过写，为什么需要Clean Code了？## Clean Code 的一些基本常识- 起名字的艺术，有意义的名字，变量，函数，参数，类，包等等 * 名副其实 * 避免误导，缩写/拼硬真的都知道吗 * 有意义的区分 ```java copy(int[] a1,int a2[]) //不如 copy(int[] source,int[] dest) 读的出来的名字 每个概念对应一个词，在一个应用中保持一致 使用已有解决方案领域的名称，比如遵循常用Design-pattern中的名称 使用业务领域中名称 添加有意义的语境名称，不使用无意义的语境名称 函数 函数名称，描述性，动词和关键字 函数变量，参数名称尽量有意义，数量尽量小于3个，善用可变参数 短小尤其是高层的函数，尽量有意义的函数组合而成(&lt;3000 行) 只做一件事情 少用switch 无副作用，比如调用有前提条件，需要注意如何更优雅的处理 setIfExist Exception 替代返回错误代码 抽离try/catch的代码 DRY:Don’t Repeat Yourself 一个入口一个出口(一个return) 注释 法律信息 代码就是注释，给变量，函数起个好名字胜过很多注释 提供信息的注释，避免无意义或者和代码不同步的注释 警示，提醒可能修改时遇到问题 TODO 放大某种看来不合理的问题，说明trade-off的情况或者特别处理的意义 修改的日志，修改的comments 格式格式是没有太多好说的，或许用一个stylecheck的工具更为好. 对象和数据结构 模块不应该了解它内部的对象情形 DTO 通信/ActiveRecord-find/search， 这些是数据结构，不要有业务逻辑 对象暴露行为，隐藏数据/数据结构暴露数据，不要有明显的行为 异常处理 异常而非返回码 使用Runtime Exception 异常信息 定义常规流程，不要返回NULL 单元测试 TDD，测试代码和业务代码，保持测试代码整齐(让人可以维护) 测试代码可读性，确保一致可以延续下去和业务保持同步(code-review,如何解决代码量打得大的问题) DSL Domain测试语言 FIRST: Fast/Independent/Repeatable/Self-Validating/Timely 类 短小，SRP 接口隔离/隔离修改 DIP 系统 DIP 工厂方法 scale out JDK代理/Proxy invocation handler/AOP/AspectJ 迭代 Run all the tests Refactor Concurrence 并发防御： SRP，Immutable Data,数据副本 ReentrantLock/Sempaphore/CoundDownLatch 执行模型 |互斥|每一个时刻只有一个线程访问共享数据和资源||线程饥饿|比如总是执行快的线程执行||死锁|两个或者多个线程相互等待||活锁|执行次序一致的线程| producer-consumer reader-writer 保持同步区域微小 关闭资源 测试线程代码/注意偶发时间(design for failure) 多平台/多处理器 stub codes/yield?? 逐步改进 work first 一步一步Refactor，from one big method to well-orgainized unit testing for refactor 味道和启发，需要细读 移除不必要的注释 函数参数不要过多，移除没有使用的函数 extract重复代码 测试不足，使用覆盖率工具，忽律的测试是不确定的，边界条件 缺陷扎堆 The Art of Readable Code表面层次的改进 naming，变量，函数，参数，类，包命名，有意义不含糊，特定，和业务领域命名一致 注释，简单，实例，描述为什么这样的理由，todo，站在读者的立场 简化循环和逻辑 if/esle的考量，正逻辑还是负逻辑更好理解 避免do/while 提前返回 最小嵌套 拆分巨大的语句 变量命名，缩小变量作用域 重新组织代码 抽取不想关的子逻到工具类或者其他相关领域 小函数也不需要太多 一次只做一件事情，通过组合函数或者类来解决大问题 想法变成代码使用自然语言程序描述功能，描述解决问题的流程 少些代码 少量代码解决最重要的问题，介绍需求 使用现有工具，unix tools/现有代码 12cat *.log | awk `&#123;print $5 &quot; &quot; $7&#125;` | egrep &quot;[45]..$&quot; \\| sort | uniq -c | sort -nr 精选话题 测试可读性 详细的错误信息 测试函数命名 可测性衡量-Hard 全局变量 外部组件大量依赖代码 代码不确定行为 可测性衡量-好 内部状态很少 类函数只做一件事情 依赖很少，可管理 函数接口简单 测试代码需要描述清楚测试的功能，高层定义越简单越好 深入阅读推荐 Code Complete Refactoring The Pragmatic Programer Javascript - The Good Parts Effective Java Design-Pattern: Elements of Reusable Object-Oriented Software Programming Pearls Joel on Software Donald E.Knuth books","categories":[],"tags":[{"name":"Notes","slug":"Notes","permalink":"http:/tags/Notes/"}]},{"title":"How To Read A Thread Dump","slug":"how-to-read-a-thread-dump","date":"2018-06-29T13:34:04.000Z","updated":"2019-07-11T01:45:11.925Z","comments":true,"path":"2018/06/29/how-to-read-a-thread-dump/","link":"","permalink":"http:/2018/06/29/how-to-read-a-thread-dump/","excerpt":"","text":"How To Read A Thread Dump Thread Terminology Thread Terminology Thread/daemon Thread, thread is discrete unit of concurrency managed by JVM daemon thread: runs independent of other threads, killed when Runtime.exit Different state Threads Alive thread - A running thread taht is performance some work Blocked thread - attempt to enter synchronized block blocked by another thread Waiting Thread - waiting for another thread to call Sleep Thread - not executing because sleep is called Monitor reference Deadlock reference Livelock Thread A performs and action that causes thread B to perform an action Thread A still alive Reference some ref: reference r2","categories":[],"tags":[{"name":"ThreadDump","slug":"ThreadDump","permalink":"http:/tags/ThreadDump/"},{"name":"Performance","slug":"Performance","permalink":"http:/tags/Performance/"},{"name":"Tip","slug":"Tip","permalink":"http:/tags/Tip/"}]},{"title":"MAVEN In 30 Minutes","slug":"0-maven-in-30-minutes","date":"2018-06-09T13:34:04.000Z","updated":"2019-07-11T01:45:21.561Z","comments":true,"path":"2018/06/09/0-maven-in-30-minutes/","link":"","permalink":"http:/2018/06/09/0-maven-in-30-minutes/","excerpt":"","text":"1- MAVEN Projects use pom.xml to describe the project dependencies,such as third party jars used use pom.xml to describe the build process,such as using build plugin to achieve specific building process use pom.xml to manage multiple projects/modules, modules are in pom.xml, modules section a lot other stuff…… 2- MAVEN Artifact VectorMAVEN Project produces an element, JAR,WAR or EAR, uniquely identified by a composite of fields known as groupId,artificatId,packing,version and scope. This vector of fields uniquely distinguishes a MAVEN artifact from all others. the samples as follow: 12groupid:artifactid:packaging:version:scopeorg.springframework:spring:jar:4.3.2:compile 3- MAVEN LifecyclesPhases,Plugins and Goals Build-in Maven Default Lifecycles: Site lifecycle 4- Maven Help123help: describe -Dplugin=&lt;plugnName&gt;mvn help:effective-pommvn help:active-profiles 5- MAVEN Dependency declaring dependencies 1234&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.yourcompany&lt;/groupId&gt; &lt;artifactId&gt;yourlib&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; declaring plugins 1234567 &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;maxmem&gt;512m&lt;/maxmem&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 6- Maven Scopescope in dependency: 7- Learning DependenciesTo Understand the dependencies for whole project,you can use following commands: 1234mvn dependency:treemvn dependency:resolve ## sortedmvn dependency:resolve-pluginsmvn dependency:analyze 8- Declaring RepositoryRepository is somewhere you can get the jars/wars 123456&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;JavaDotNetRepo&lt;/id&gt; &lt;url&gt;https://maven-repository.dev.java.net&lt;/url&gt; &lt;/repository&gt;&lt;/repositories&gt; 9- Maven Properties Prefefined Properties self defined properties 12345&lt;project&gt; &lt;properties&gt; &lt;my.somevar&gt;My Value&lt;/my.somevar&gt; &lt;/properties&gt;&lt;/project&gt; 10- Maven Debugcommands for debug: 123mvn -e # stacktracemvn -X #mvnDebug &lt;projectName&gt; 11- Maven Profile activation1mvn -P profileName profile setting: 1234567891011&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;YourProfile&lt;/id&gt; [...settings, build, etc...] &lt;activation&gt; &lt;os&gt; &lt;name&gt;Windows XP&lt;/name&gt; &lt;family&gt;Windows&lt;/family&gt; &lt;arch&gt;x86&lt;/arch&gt; &lt;version&gt;5.1.2600&lt;/version&gt; &lt;/os&gt; &lt;file&gt; &lt;missing&gt;somefolder/somefile.txt&lt;/missing&gt; &lt;/file&gt; &lt;/activation&gt; &lt;/profile&gt;&lt;/profiles&gt; ##12- Maven Release 12mvn release: reparemvn release: perform 13- Maven Reportsreports defined in reporting section, these reports could be coverage report, and any other reports.","categories":[],"tags":[{"name":"MAVEN","slug":"MAVEN","permalink":"http:/tags/MAVEN/"},{"name":"CI/CD","slug":"CI-CD","permalink":"http:/tags/CI-CD/"},{"name":"Project Setup","slug":"Project-Setup","permalink":"http:/tags/Project-Setup/"}]},{"title":"Word Frequency - Use JDK Methods","slug":"0-word-frequency","date":"2018-06-07T17:50:03.000Z","updated":"2019-07-11T01:44:35.744Z","comments":true,"path":"2018/06/08/0-word-frequency/","link":"","permalink":"http:/2018/06/08/0-word-frequency/","excerpt":"","text":"What is the problemBe confidence to the JDK, in most case, it is enough to solve problem. Here is a case, an issue to solve: There are over 10000 files in a dir Try to find out the top 100 most frequency words in these files, estimate 10 millions words out there Try to use I didn’t sovle it in 40 mintues, the failure part is just think too much about the data structure and algorithm. I just did some investigation then, and find out actually JDK methods are enough. Here is my thought, and I think need to implement my own algorithm to solve, actually I am wrong, JDK is enough Read the files Put word and count to a concurrent map get the top 100 from the map Because I am a fraid the memory and other resource issue, but later I had my try, it looks like worked if only use JDK methods. Here comes my solution. SolutionFirst of all, I try to create 10000 files with some random string(word),all strings are less than 18 characters, the codes are : 123456789101112131415161718192021222324252627282930313233343536373839404142static String getSaltString() &#123; String SALTCHARS = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890\"; StringBuilder salt = new StringBuilder(); Random rnd = new Random(); int strLength = rnd.nextInt(10); if(strLength&lt;=2)&#123; strLength =3; &#125; while (salt.length() &lt; strLength) &#123; // length of the random string. int index = (int) (rnd.nextFloat() * SALTCHARS.length()); salt.append(SALTCHARS.charAt(index)); &#125; String saltStr = salt.toString(); return saltStr; &#125; private static List&lt;String&gt; createRandomFile() &#123; List&lt;String&gt; result = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 1000; i++) &#123; List&lt;String&gt; listString = new ArrayList&lt;&gt;(); for (int j = 0; j &lt; 50; j++) &#123; listString.add(getSaltString()); &#125; StringBuilder sb = new StringBuilder(); for (String s : listString) &#123; sb.append(\" \").append(s); &#125; result.add(sb.toString()); &#125; return result; &#125; private static void createFile(int i, List&lt;String&gt; values) throws IOException &#123; Files.write(Paths.get(\"tmp/\" + i), values); &#125; private static void createFiles(int fileNum) throws IOException &#123; for (int i = 0; i &lt; fileNum; i++) &#123; createFile(i, createRandomFile()); &#125; &#125; then I tried use to read files and put words into frequency map,and here multiple threads are used 12345678910111213141516171819202122232425262728293031 private static void readAndPutTo(Path path) throws IOException &#123; List&lt;String&gt; lines = Files.readAllLines(path); for (String line : lines) &#123; String[] words = line.split(\"\\\\s+\"); for (String word : words) &#123; frenquncyMap.put(word, frenquncyMap.getOrDefault(word, 0) + 1); &#125; &#125; &#125;public static void main(args[])&#123;ExecutorService es = Executors.newFixedThreadPool(30); System.out.println(Files.list(Paths.get(\"tmp\")).count()); Files.list(Paths.get(\"tmp\")).forEach( path -&gt; &#123; count.getAndIncrement(); try &#123; readAndPutTo(path); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; ); System.out.println(\"completed tasks: \"+count); long end = System.currentTimeMillis(); System.out.println(end - start); es.shutdown(); System.out.println(es.awaitTermination(120, TimeUnit.SECONDS); System.out.println(System.currentTimeMillis() - start);&#125; Use shutdown() to make sure every tasks are completed, and print the task count to check if all tasks had be invoked. At last use stream api to list top 100 work frequency. 12345678List result = frenquncyMap.entrySet().stream() .sorted(Map.Entry.comparingByValue()) .limit(100).collect(Collectors.toList());System.out.println(result);System.out.println(System.currentTimeMillis() - start);Files.delete(Paths.get(\"tmp/\"));Files.createDirectories(Paths.get(\"tmp/\")); That’s it, let’s run and see what happened: 12 Later I willl jump into JDK, to understand what the algorithm used in JDK.","categories":[],"tags":[{"name":"interview","slug":"interview","permalink":"http:/tags/interview/"},{"name":"word_frequency","slug":"word-frequency","permalink":"http:/tags/word-frequency/"},{"name":"algorithm","slug":"algorithm","permalink":"http:/tags/algorithm/"}]},{"title":"font-tips","slug":"font-tips_May","date":"2018-05-20T13:29:37.000Z","updated":"2019-07-11T01:45:11.810Z","comments":true,"path":"2018/05/20/font-tips_May/","link":"","permalink":"http:/2018/05/20/font-tips_May/","excerpt":"","text":"Tips Here for change api.googlefont like site to an avaible site. For Font https://fonts.lug.ustc.edu.cn/ https://fonts.css.network/ Other FrontEnd Resources1234567891011常用前端公共库https://cdn.css.net/ Google 公共库https://ajax.css.network/ Gravatarhttps://gravatar.css.network/ Google 字体库https://fonts.css.network/","categories":[],"tags":[{"name":"tips","slug":"tips","permalink":"http:/tags/tips/"}]}]}